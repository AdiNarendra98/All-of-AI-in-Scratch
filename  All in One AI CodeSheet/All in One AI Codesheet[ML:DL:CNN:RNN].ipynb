{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# All in One Popular ML/NN/CNN/RNN Models Implementation üìä üíªüßê","metadata":{"id":"jmfoOuEg7vZv"}},{"cell_type":"markdown","source":"<a id=\"cell-intro\"></a>\n# 1. Introduction","metadata":{"id":"99r8-44l7nbe"}},{"cell_type":"markdown","source":"This cheatsheet contains:\n\n1.   **Popular Machine Learning Models**\n2.   **(Deep) Neural Networks**\n3.   **Convolutional Neural Networks**\n4.   **Recurrent Neural Networks**\n5.   **Natural Language Processing**\n\nAlways import \"[‚ö†Ô∏è Global Libraries for every project ‚ö†Ô∏è](#cell-global_lib)\" first to make anything else work within this notebook.\n\nThe datasets used are:\n1. [Alpaca Dataset for Image Classification](https://www.kaggle.com/datasets/sid4sal/alpaca-dataset-small)\n2. [Best regression model](https://www.kaggle.com/datasets/anshulkataria/best-regression-model)\n3. [Breast Tumor Features](https://www.kaggle.com/datasets/ayushish12/breast-tumor-features)\n4. [Car Object Detection](https://www.kaggle.com/datasets/sshikamaru/car-object-detection)\n5. [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)  \n6. [Rearranged Brain Tumor dataset](https://www.kaggle.com/datasets/nsff591/rearranged-brain-tumor-dataset-from-ahmed-hamada)\n7. [Restaurant Reviews](https://www.kaggle.com/datasets/nanuprasad/restaurant-reviews) \n8. [Semantic Segmentation for Self Driving Cars](https://www.kaggle.com/datasets/kumaresanmanickavelu/lyft-udacity-challenge)\n9. [Ubiquant Market Prediction Pickle Dataset](https://www.kaggle.com/datasets/lonnieqin/ubiquant-market-prediction-half-precision-pickle)\n10. [White Wine Quality](https://www.kaggle.com/datasets/piyushagni5/white-wine-quality)\n\n\n","metadata":{"id":"yntNvbnn7raR"}},{"cell_type":"markdown","source":"<a id=\"cell-toc\"></a>\n# 2. Table of Content","metadata":{"id":"JJ0HCUBO8zqK"}},{"cell_type":"markdown","source":"1 [Introduction](#cell-intro)\n\n2 [Table of Content](#cell-toc)\n\n3 [Model Explanation and Implementation](#cell-models)\n\n[‚ö†Ô∏è Global Libraries for every project ‚ö†Ô∏è](#cell-global_lib)\n\n3.1 [Basic Regression](#cell-basic_regression)\n\n* [Importing simple regression data](#cell-basic_regression_import)\n1.  [Linear Regression](#cell-basic_linear_regression)\n2.  [Multi-linear regression](#cell-basic_multi_linear_regression)\n3.  [Polynomial regression](#cell-basic_poly_regression)\n4.  [Decision tree regression](#cell-basic_dtr)\n5.  [Random forest regression](#cell-basic_rfr)\n6.  [Support Vector regression](#cell-basic_svmr)\n\n3.2 [Basic Classification](#cell-basic_c)\n\n* [Importing Simple classification data](#cell-basic_c_data)\n\n1.  [Logistic regression](#cell-basic_c_lr)\n2.  [Naive bayes](#cell-basic_c_nb)\n3.  [K nearest neighbours(KNN)](#cell-basic_c_knn)\n4.  [Suport vector machine (SVM)](#cell-basic_c_svm)\n5.  [Kernel SVM](#cell-basic_c_ksvm)\n6.  [Decision tree classification](#cell-basic_c_dtc)\n7.  [Random forest classification](#cell-basic_c_rfc)\n____\n*(the following models can also be used for regression)*\n\n8.  [LightLGBM model](#cell-basic_c_lgbm)\n9.  [XGBoost model](#cell-basic_c_xgbm)\n10. [Catboost model](#cell-basic_c_cbm)\n\n3.3 [Neural Networks (NN)](#cell-nn)\n\n* [Importing Simple NN data](#cell-nn_data)\n\n1. [Neural Network: Sequential() keras](#cell-nn_seq)\n2. [Neural Network: Functional Keras](#cell-nn_func)\n3. [Neural Network: PyTorch](#cell-nn_pytorch)\n4. [Self Organizing Maps (SOM)](#cell-nn_som)\n5. [Boltzman Machine](#cell-nn_bm)\n6. [AutoEncoders](#cell-nn_ae)\n\n3.4 [Convolutional Neural Networks (CNN)](#cell-cnn)\n\n* [Importing Simple CNN data](#cell-cnn_data)\n\n1. [Convolutional Neural Network: Sequential() keras](#cell-cnn_seq)\n2. [Convolutional Neural Network: Functional keras](#cell-cnn_func)\n3. [Skip Connections/Residual blocks](#cell-cnn_skip)\n4. [Inception Network](#cell-cnn_incept)\n5. [Depthwise Separable Convolution](#cell-cnn_dsc)\n6. [Transfer Learning](#cell-cnn_tran)\n7. [Object Detection](#cell-cnn_obj)\n8. [Semantic Segmentation](#cell-cnn_semantic_seg)\n9. [Face Recognition](#cell-cnn_face_rec)\n10. [Neural Style Transfer](#cell-cnn_style_transf)\n\n* [Importing Simple CNN data](#cell-cnn_data)\n\n3.5 [Recurrent Neural Networks (RNN)](#cell-rnn)\n\n* [Importing Simple RNN data](#cell-rnn_data)\n1. [Long short-term memory (LSTM)](#cell-rnn_lstm)\n\n3.6 [Natural Language Processing (NLP)](#cell-nlp)\n1. [Sentiment Analysis](#cell-nlp_sent)\n\n4 [References](#cell-references)","metadata":{"id":"D2p-gBYNumld"}},{"cell_type":"markdown","source":"<a id=\"cell-models\"></a>\n# 3. Model Explanation and Implementation","metadata":{"id":"9TR3JX4Is6n7"}},{"cell_type":"markdown","source":"<a id=\"cell-global_lib\"></a>\n## ‚ö†Ô∏è Global Libraries for every project ‚ö†Ô∏è","metadata":{"id":"1JG0krZDx76Z"}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"id":"zXs9iMLc0Tlw","executionInfo":{"status":"ok","timestamp":1649077159014,"user_tz":-120,"elapsed":436,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"execution":{"iopub.status.busy":"2022-04-12T14:46:08.01846Z","iopub.execute_input":"2022-04-12T14:46:08.019215Z","iopub.status.idle":"2022-04-12T14:46:08.849675Z","shell.execute_reply.started":"2022-04-12T14:46:08.019117Z","shell.execute_reply":"2022-04-12T14:46:08.848979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_regression\"></a>\n## 3.1 Basic Regression","metadata":{"id":"aGAs8S7JuQsP"}},{"cell_type":"markdown","source":"<a id=\"cell-basic_regression_import\"></a>\n### Importing Simple Regression data","metadata":{"id":"UxttMdmUytqw"}},{"cell_type":"code","source":"regressionDataset = pd.read_csv('../input/best-regression-model/Data.csv')\nx = regressionDataset.iloc[:, :-1].values\ny = regressionDataset.iloc[:, -1].values\n\nprint(\"Dimensions: \" + str(regressionDataset.shape))","metadata":{"id":"QMI5rv5UzOyZ","executionInfo":{"status":"ok","timestamp":1649077159909,"user_tz":-120,"elapsed":514,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"a716a10a-ec2e-4a2a-a08a-5b6ab38dca61","execution":{"iopub.status.busy":"2022-04-07T11:35:09.104182Z","iopub.execute_input":"2022-04-07T11:35:09.104449Z","iopub.status.idle":"2022-04-07T11:35:09.138313Z","shell.execute_reply.started":"2022-04-07T11:35:09.10441Z","shell.execute_reply":"2022-04-07T11:35:09.137048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regressionDataset.head()","metadata":{"id":"6_QcTyXm0iQ-","executionInfo":{"status":"ok","timestamp":1649077159911,"user_tz":-120,"elapsed":68,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"31fba4af-a4c3-4585-b75d-1a5a30b202a5","execution":{"iopub.status.busy":"2022-04-07T11:35:09.139499Z","iopub.execute_input":"2022-04-07T11:35:09.139777Z","iopub.status.idle":"2022-04-07T11:35:09.160944Z","shell.execute_reply.started":"2022-04-07T11:35:09.13974Z","shell.execute_reply":"2022-04-07T11:35:09.16022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","metadata":{"id":"zDVL8o_92H9r","executionInfo":{"status":"ok","timestamp":1649077159913,"user_tz":-120,"elapsed":65,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"execution":{"iopub.status.busy":"2022-04-07T11:35:09.1627Z","iopub.execute_input":"2022-04-07T11:35:09.163003Z","iopub.status.idle":"2022-04-07T11:35:09.169428Z","shell.execute_reply.started":"2022-04-07T11:35:09.162969Z","shell.execute_reply":"2022-04-07T11:35:09.167933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_linear_regression\"></a>\n### 3.1.1. Linear Regression","metadata":{"id":"IHOSwP-jvE2S"}},{"cell_type":"markdown","source":"<img src=\"https://www.reneshbedre.com/assets/posts/reg/reg_front.svg\" width=\"650\" align=\"centr\"/>","metadata":{"id":"Q6lUkVqGvLPd"}},{"cell_type":"markdown","source":"<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/8119b3ed1259aa8ff15166488548104b50a0f92e\" width=\"150\" align=\"centr\"/>","metadata":{"id":"H-OQUK9dv63o"}},{"cell_type":"markdown","source":"Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable. The model will alter the Œ≤ and Œµ to fit the model.","metadata":{"id":"SOqn8OQ8xuFA"}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(x_train, y_train)","metadata":{"id":"7IESUvMa2CPf","executionInfo":{"status":"ok","timestamp":1649077159915,"user_tz":-120,"elapsed":66,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"d790cb12-e130-4b04-a7ee-57eb4be253e6","execution":{"iopub.status.busy":"2022-04-07T11:35:09.234766Z","iopub.execute_input":"2022-04-07T11:35:09.235041Z","iopub.status.idle":"2022-04-07T11:35:09.315927Z","shell.execute_reply.started":"2022-04-07T11:35:09.235013Z","shell.execute_reply":"2022-04-07T11:35:09.315152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\ny_pred = regressor.predict(x_test)\nr2_score(y_test, y_pred)","metadata":{"id":"_e0EJ16w3SI1","executionInfo":{"status":"ok","timestamp":1649077159917,"user_tz":-120,"elapsed":59,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"23841168-7474-416d-c471-d046b8fd1793","execution":{"iopub.status.busy":"2022-04-07T11:35:09.532929Z","iopub.execute_input":"2022-04-07T11:35:09.533154Z","iopub.status.idle":"2022-04-07T11:35:09.543787Z","shell.execute_reply.started":"2022-04-07T11:35:09.533128Z","shell.execute_reply":"2022-04-07T11:35:09.543056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: R¬≤ cannot be used for nonlinear regression but is a good indicator for linear regressions. (the closer to 1 the better)","metadata":{"id":"SxUNrwhyrLMx"}},{"cell_type":"code","source":"plt.scatter(y_test,y_pred)","metadata":{"id":"BcLBAktBCHau","executionInfo":{"status":"ok","timestamp":1649077159918,"user_tz":-120,"elapsed":54,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"6f0729ee-60b5-4c85-f9d8-9450ce2c1765","execution":{"iopub.status.busy":"2022-04-07T11:35:09.833135Z","iopub.execute_input":"2022-04-07T11:35:09.833402Z","iopub.status.idle":"2022-04-07T11:35:10.079022Z","shell.execute_reply.started":"2022-04-07T11:35:09.833372Z","shell.execute_reply":"2022-04-07T11:35:10.078373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we would have a perfect straight line, this would mean R¬≤ would be 1 and our predictive model would have been 100% accurate. This is not the case but the shape of the scatter plot does show that we can predict pretty close to it and we even notice some outliers which can be tracked down with further research on the dataset if we wanted to.","metadata":{"id":"YTt1hUhTEUEj"}},{"cell_type":"markdown","source":"<a id=\"cell-basic_multi_linear_regression\"></a>\n### 3.1.2. Multi-linear regression","metadata":{"id":"c7W_ZtyXFl7q"}},{"cell_type":"markdown","source":"**Difference between Linear and multi-linear regression:**\n\nSimple linear regression has only one x and one y variable.\nMultiple linear regression has one y and two or more x variables/features.\n\nWe actually use a multi-linear dataset here, which means that our previous **Linear regression code is the same for the multi-linear version.** ","metadata":{"id":"ZzV3ZoWmGzAx"}},{"cell_type":"markdown","source":"<a name=\"cell-basic_poly_regression\"></a>\n### 3.1.3. Polynomial regression","metadata":{"id":"RyihHbC3HiF9"}},{"cell_type":"markdown","source":"<img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/machine-learning-polynomial-regression.png\" width=\"650\" align=\"centr\"/>","metadata":{"id":"uDix91k4Hq_g"}},{"cell_type":"markdown","source":"<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/bc6e10cc75097fa66e7e02d6a75491d14a0c4aba\" width=\"500\" align=\"centr\"/>","metadata":{"id":"s6kBL-ajIAgo"}},{"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\npoly_reg = PolynomialFeatures(degree = 4) # degrees = amount of features (= amount of x variables)\nx_poly = poly_reg.fit_transform(x_train)\nregressor = LinearRegression()\nregressor.fit(x_poly, y_train)","metadata":{"id":"Oea57mwLIgNu","executionInfo":{"status":"ok","timestamp":1649077159921,"user_tz":-120,"elapsed":48,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"112459d4-9f38-4612-e96b-6e6b935acc3f","execution":{"iopub.status.busy":"2022-04-07T11:35:10.140332Z","iopub.execute_input":"2022-04-07T11:35:10.140763Z","iopub.status.idle":"2022-04-07T11:35:10.182011Z","shell.execute_reply.started":"2022-04-07T11:35:10.14073Z","shell.execute_reply":"2022-04-07T11:35:10.181257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\ny_pred = regressor.predict(poly_reg.transform(x_test))\nr2_score(y_test, y_pred)","metadata":{"id":"LZcEa-WrI_Nb","executionInfo":{"status":"ok","timestamp":1649077159921,"user_tz":-120,"elapsed":40,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"26b58263-3f5c-4610-806d-8f31f949947c","execution":{"iopub.status.busy":"2022-04-07T11:35:10.446773Z","iopub.execute_input":"2022-04-07T11:35:10.447011Z","iopub.status.idle":"2022-04-07T11:35:10.460727Z","shell.execute_reply.started":"2022-04-07T11:35:10.446983Z","shell.execute_reply":"2022-04-07T11:35:10.459921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(y_test,y_pred)","metadata":{"id":"Hy4AvPaOJNBg","executionInfo":{"status":"ok","timestamp":1649077160470,"user_tz":-120,"elapsed":578,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"51d13613-15d8-499f-c06c-d2b225036b7d","execution":{"iopub.status.busy":"2022-04-07T11:35:10.746616Z","iopub.execute_input":"2022-04-07T11:35:10.746842Z","iopub.status.idle":"2022-04-07T11:35:10.950009Z","shell.execute_reply.started":"2022-04-07T11:35:10.746816Z","shell.execute_reply":"2022-04-07T11:35:10.949337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_dtr\"></a>\n### 3.1.4. Decision tree regression","metadata":{"id":"xF1FaWX2Jnnb"}},{"cell_type":"markdown","source":"<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_tree_regression_001.png\" width=\"650\" align=\"centr\"/>","metadata":{"id":"2f7dXMiTJqzT"}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor(random_state = 0)\nregressor.fit(x_train, y_train)","metadata":{"id":"L2WU9WYTKuWU","executionInfo":{"status":"ok","timestamp":1649077160472,"user_tz":-120,"elapsed":31,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"c952200b-b528-4706-d800-d9da031ee39b","execution":{"iopub.status.busy":"2022-04-07T11:35:11.040546Z","iopub.execute_input":"2022-04-07T11:35:11.040847Z","iopub.status.idle":"2022-04-07T11:35:11.143735Z","shell.execute_reply.started":"2022-04-07T11:35:11.04082Z","shell.execute_reply":"2022-04-07T11:35:11.143077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\ny_pred = regressor.predict(x_test)\nr2_score(y_test, y_pred)","metadata":{"id":"gyR2AQDFK31O","executionInfo":{"status":"ok","timestamp":1649077160473,"user_tz":-120,"elapsed":26,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"839c9cfc-f51c-439b-fd54-dab7925ce0a0","execution":{"iopub.status.busy":"2022-04-07T11:35:11.338609Z","iopub.execute_input":"2022-04-07T11:35:11.339316Z","iopub.status.idle":"2022-04-07T11:35:11.347838Z","shell.execute_reply.started":"2022-04-07T11:35:11.339248Z","shell.execute_reply":"2022-04-07T11:35:11.347058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(y_test,y_pred)","metadata":{"id":"p6E-YxOUK-si","executionInfo":{"status":"ok","timestamp":1649077160907,"user_tz":-120,"elapsed":455,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"de0d8d22-5d03-4960-8d70-1324b9a97fe7","execution":{"iopub.status.busy":"2022-04-07T11:35:11.658854Z","iopub.execute_input":"2022-04-07T11:35:11.659097Z","iopub.status.idle":"2022-04-07T11:35:11.866967Z","shell.execute_reply.started":"2022-04-07T11:35:11.659069Z","shell.execute_reply":"2022-04-07T11:35:11.86619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_rfr\"></a>\n### 3.1.5. Random forest regression","metadata":{"id":"D00e_WKrLOqF"}},{"cell_type":"markdown","source":"<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/76/Random_forest_diagram_complete.png\" width=\"650\" align=\"centr\"/>","metadata":{"id":"-wIAtq2RLTLt"}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\nregressor.fit(x_train, y_train)","metadata":{"id":"Q25Q58-vLlRU","executionInfo":{"status":"ok","timestamp":1649077160908,"user_tz":-120,"elapsed":25,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"d014ccc2-4cc9-4c66-a58b-14a203946e3b","execution":{"iopub.status.busy":"2022-04-07T11:35:11.980395Z","iopub.execute_input":"2022-04-07T11:35:11.980602Z","iopub.status.idle":"2022-04-07T11:35:12.237421Z","shell.execute_reply.started":"2022-04-07T11:35:11.980576Z","shell.execute_reply":"2022-04-07T11:35:12.236618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\ny_pred = regressor.predict(x_test)\nr2_score(y_test, y_pred)","metadata":{"id":"2DIkzsdPMED4","executionInfo":{"status":"ok","timestamp":1649077160910,"user_tz":-120,"elapsed":20,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"9758bb22-beed-4ba6-cb45-fffa8fba9d98","execution":{"iopub.status.busy":"2022-04-07T11:35:12.296571Z","iopub.execute_input":"2022-04-07T11:35:12.296761Z","iopub.status.idle":"2022-04-07T11:35:12.310582Z","shell.execute_reply.started":"2022-04-07T11:35:12.296737Z","shell.execute_reply":"2022-04-07T11:35:12.309956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(y_test,y_pred)","metadata":{"id":"QVDuNGs0MIqW","executionInfo":{"status":"ok","timestamp":1649077161453,"user_tz":-120,"elapsed":558,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"a07db8d2-0be0-4782-ae9c-c95ce3a11ce4","execution":{"iopub.status.busy":"2022-04-07T11:35:12.616917Z","iopub.execute_input":"2022-04-07T11:35:12.617159Z","iopub.status.idle":"2022-04-07T11:35:12.817755Z","shell.execute_reply.started":"2022-04-07T11:35:12.617131Z","shell.execute_reply":"2022-04-07T11:35:12.817109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_svmr\"></a>\n### 3.1.6. Support Vector regression","metadata":{"id":"xjrRVqDUMZJz"}},{"cell_type":"markdown","source":"<img src=\"https://i.stack.imgur.com/29nu8.png\" width=\"650\" align=\"centr\"/>","metadata":{"id":"XA5DQkXWMhJO"}},{"cell_type":"markdown","source":"**Feature scaling is needed with SVM**","metadata":{"id":"G09tQs5tNvPq"}},{"cell_type":"code","source":"y_svm = y.reshape(len(y),1)\n\nx_train, x_test, y_svm_train, y_svm_test = train_test_split(x, y_svm, test_size = 0.2, random_state = 0)\n\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nsc_y = StandardScaler()\nx_svm_train = sc_x.fit_transform(x_train)\ny_svm_train = sc_y.fit_transform(y_svm_train)","metadata":{"id":"9oZVJQIVNuz4","executionInfo":{"status":"ok","timestamp":1649077161454,"user_tz":-120,"elapsed":16,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"execution":{"iopub.status.busy":"2022-04-07T11:35:12.958763Z","iopub.execute_input":"2022-04-07T11:35:12.958964Z","iopub.status.idle":"2022-04-07T11:35:12.969231Z","shell.execute_reply.started":"2022-04-07T11:35:12.95894Z","shell.execute_reply":"2022-04-07T11:35:12.968482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVR\nregressor = SVR(kernel = 'rbf')\nregressor.fit(x_svm_train, y_svm_train)","metadata":{"id":"3JBXKS89NCfk","executionInfo":{"status":"ok","timestamp":1649077164230,"user_tz":-120,"elapsed":2791,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"4ad631eb-f948-4126-95be-7d8c2d8e2535","execution":{"iopub.status.busy":"2022-04-07T11:35:13.370768Z","iopub.execute_input":"2022-04-07T11:35:13.371036Z","iopub.status.idle":"2022-04-07T11:35:15.219017Z","shell.execute_reply.started":"2022-04-07T11:35:13.371004Z","shell.execute_reply":"2022-04-07T11:35:15.21834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\ny_pred = sc_y.inverse_transform(regressor.predict(sc_x.transform(x_test)).reshape(-1,1))\nr2_score(y_svm_test, y_pred)","metadata":{"id":"DQc23XmTNCze","executionInfo":{"status":"ok","timestamp":1649077164769,"user_tz":-120,"elapsed":547,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"9b29261c-80ca-46b0-ab0e-948fc8809cce","execution":{"iopub.status.busy":"2022-04-07T11:35:15.220757Z","iopub.execute_input":"2022-04-07T11:35:15.221017Z","iopub.status.idle":"2022-04-07T11:35:15.589989Z","shell.execute_reply.started":"2022-04-07T11:35:15.220982Z","shell.execute_reply":"2022-04-07T11:35:15.58924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(y_svm_test,y_pred)","metadata":{"id":"a21DnRdONC8l","executionInfo":{"status":"ok","timestamp":1649077164771,"user_tz":-120,"elapsed":18,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"41b8ff63-81fd-4c9f-87d8-1c362bc02d82","execution":{"iopub.status.busy":"2022-04-07T11:35:15.591124Z","iopub.execute_input":"2022-04-07T11:35:15.591399Z","iopub.status.idle":"2022-04-07T11:35:15.796362Z","shell.execute_reply.started":"2022-04-07T11:35:15.591361Z","shell.execute_reply":"2022-04-07T11:35:15.795705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_c\"></a>\n## 3.2 Basic Classification","metadata":{"id":"hpiK4N0XQoit"}},{"cell_type":"markdown","source":"<a id=\"cell-basic_c_data\"></a>\n### Importing Simple classification data","metadata":{"id":"cjQkicx_Qtkl"}},{"cell_type":"code","source":"dataset = pd.read_csv('../input/breast-tumor-features/breast tumor.csv')\nx = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\nprint(\"Dimensions: \" + str(dataset.shape))","metadata":{"id":"gNyLNCIYQ2z5","executionInfo":{"status":"ok","timestamp":1649077165729,"user_tz":-120,"elapsed":969,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"45cdcb5f-e9a8-40da-e4cc-2217a30e0bd8","execution":{"iopub.status.busy":"2022-04-07T11:35:15.798154Z","iopub.execute_input":"2022-04-07T11:35:15.798844Z","iopub.status.idle":"2022-04-07T11:35:15.81771Z","shell.execute_reply.started":"2022-04-07T11:35:15.798806Z","shell.execute_reply":"2022-04-07T11:35:15.816902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"id":"ZYG17KnDdFMp","executionInfo":{"status":"ok","timestamp":1649077165731,"user_tz":-120,"elapsed":87,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"df7e8279-706c-4f81-92b8-a5e71a1365ee","execution":{"iopub.status.busy":"2022-04-07T11:35:15.819162Z","iopub.execute_input":"2022-04-07T11:35:15.819424Z","iopub.status.idle":"2022-04-07T11:35:15.829638Z","shell.execute_reply.started":"2022-04-07T11:35:15.819391Z","shell.execute_reply":"2022-04-07T11:35:15.82896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)","metadata":{"id":"xzO0b_zTb8_w","executionInfo":{"status":"ok","timestamp":1649077165732,"user_tz":-120,"elapsed":83,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"execution":{"iopub.status.busy":"2022-04-07T11:35:15.8309Z","iopub.execute_input":"2022-04-07T11:35:15.831389Z","iopub.status.idle":"2022-04-07T11:35:15.838683Z","shell.execute_reply.started":"2022-04-07T11:35:15.831282Z","shell.execute_reply":"2022-04-07T11:35:15.837949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","metadata":{"id":"PktiWlMhcGXA","executionInfo":{"status":"ok","timestamp":1649077165733,"user_tz":-120,"elapsed":82,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"execution":{"iopub.status.busy":"2022-04-07T11:35:15.839993Z","iopub.execute_input":"2022-04-07T11:35:15.840238Z","iopub.status.idle":"2022-04-07T11:35:15.848044Z","shell.execute_reply.started":"2022-04-07T11:35:15.840206Z","shell.execute_reply":"2022-04-07T11:35:15.847323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_c_lr\"></a>\n### 3.2.1. Logistic regression","metadata":{"id":"20TzYeZsbITQ"}},{"cell_type":"markdown","source":"<img src=\"https://rajputhimanshu.files.wordpress.com/2018/03/linear_vs_logistic_regression.jpg\" width=\"650\" align=\"centr\"/>","metadata":{"id":"flqXbqylcgKp"}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(x_train, y_train)","metadata":{"id":"MUYrqnAzcqs4","executionInfo":{"status":"ok","timestamp":1649077165733,"user_tz":-120,"elapsed":81,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"4fe1d2fe-4821-435b-bede-1349f9ad8f7c","execution":{"iopub.status.busy":"2022-04-07T11:35:15.849466Z","iopub.execute_input":"2022-04-07T11:35:15.849765Z","iopub.status.idle":"2022-04-07T11:35:15.863781Z","shell.execute_reply.started":"2022-04-07T11:35:15.849732Z","shell.execute_reply":"2022-04-07T11:35:15.862993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","metadata":{"id":"Bth_wwcRcygT","executionInfo":{"status":"ok","timestamp":1649077165734,"user_tz":-120,"elapsed":74,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"9959726e-f2df-441d-a020-9b975a3bedd3","execution":{"iopub.status.busy":"2022-04-07T11:35:15.864878Z","iopub.execute_input":"2022-04-07T11:35:15.865249Z","iopub.status.idle":"2022-04-07T11:35:15.875705Z","shell.execute_reply.started":"2022-04-07T11:35:15.865217Z","shell.execute_reply":"2022-04-07T11:35:15.874824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_c_nb\"></a>\n### 3.2.2. Naive Bayes","metadata":{"id":"XJsBM3hYeJ50"}},{"cell_type":"markdown","source":"<img src=\"https://thatware.co/wp-content/uploads/2020/04/naive-bayes.png\" width=\"650\" align=\"centr\"/>","metadata":{"id":"OszZtyuIeWk4"}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(x_train, y_train)","metadata":{"id":"mub2sXqWglqN","executionInfo":{"status":"ok","timestamp":1649077165735,"user_tz":-120,"elapsed":70,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"7dc618e3-3437-432c-d849-c986fa91d43d","execution":{"iopub.status.busy":"2022-04-07T11:35:15.968679Z","iopub.execute_input":"2022-04-07T11:35:15.969354Z","iopub.status.idle":"2022-04-07T11:35:15.978009Z","shell.execute_reply.started":"2022-04-07T11:35:15.969316Z","shell.execute_reply":"2022-04-07T11:35:15.977097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","metadata":{"id":"BDTQNaOJgu5d","executionInfo":{"status":"ok","timestamp":1649077165736,"user_tz":-120,"elapsed":66,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"bd26cbf7-8f21-4b44-8d9a-6d92989ba913","execution":{"iopub.status.busy":"2022-04-07T11:35:16.256781Z","iopub.execute_input":"2022-04-07T11:35:16.25702Z","iopub.status.idle":"2022-04-07T11:35:16.269056Z","shell.execute_reply.started":"2022-04-07T11:35:16.256994Z","shell.execute_reply":"2022-04-07T11:35:16.268122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_c_knn\"></a>\n### 3.2.3. K-nearest neighbours (KNN)","metadata":{"id":"OgsZ93G9hZjW"}},{"cell_type":"markdown","source":"<img src=\"https://raw.githubusercontent.com/artifabrian/dynamic-knn-gpu/master/knn.png\" width=\"650\" align=\"centr\"/>","metadata":{"id":"ylQ93_68hdsQ"}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(x_train, y_train)","metadata":{"id":"dWdvz7R0htl7","executionInfo":{"status":"ok","timestamp":1649077165737,"user_tz":-120,"elapsed":61,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"804df093-fbe7-4b7a-e303-4ea884861fdf","execution":{"iopub.status.busy":"2022-04-07T11:35:16.542835Z","iopub.execute_input":"2022-04-07T11:35:16.54318Z","iopub.status.idle":"2022-04-07T11:35:16.553169Z","shell.execute_reply.started":"2022-04-07T11:35:16.543146Z","shell.execute_reply":"2022-04-07T11:35:16.552241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","metadata":{"id":"IPYFyLezh5wE","executionInfo":{"status":"ok","timestamp":1649077165738,"user_tz":-120,"elapsed":56,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"63a1b57a-2c23-4233-8cb0-454711b24f36","execution":{"iopub.status.busy":"2022-04-07T11:35:16.826633Z","iopub.execute_input":"2022-04-07T11:35:16.826874Z","iopub.status.idle":"2022-04-07T11:35:16.845361Z","shell.execute_reply.started":"2022-04-07T11:35:16.826847Z","shell.execute_reply":"2022-04-07T11:35:16.844664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_c_svm\"></a>\n### 3.2.4. Suport vector machine (SVM)","metadata":{"id":"5ca6NuDsh-gF"}},{"cell_type":"markdown","source":"<img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/support-vector-machine-algorithm.png\" width=\"650\" align=\"centr\"/>","metadata":{"id":"AHiz8D8EiZaB"}},{"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(x_train, y_train)","metadata":{"id":"6TtkISjhiwU9","executionInfo":{"status":"ok","timestamp":1649077165739,"user_tz":-120,"elapsed":51,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"4a89d076-6e7b-4c1b-d1bf-def2336d8a90","execution":{"iopub.status.busy":"2022-04-07T11:35:17.117818Z","iopub.execute_input":"2022-04-07T11:35:17.11976Z","iopub.status.idle":"2022-04-07T11:35:17.130791Z","shell.execute_reply.started":"2022-04-07T11:35:17.119725Z","shell.execute_reply":"2022-04-07T11:35:17.130017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","metadata":{"id":"QxiPaiV0jDzF","executionInfo":{"status":"ok","timestamp":1649077165744,"user_tz":-120,"elapsed":50,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"77e5ff26-c647-4527-9ab8-345baa71bc1a","execution":{"iopub.status.busy":"2022-04-07T11:35:17.400715Z","iopub.execute_input":"2022-04-07T11:35:17.401244Z","iopub.status.idle":"2022-04-07T11:35:17.414588Z","shell.execute_reply.started":"2022-04-07T11:35:17.401212Z","shell.execute_reply":"2022-04-07T11:35:17.413831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_c_ksvm\"></a>\n### 3.2.5. Kernel SVM","metadata":{"id":"PcxfB3gkjF7g"}},{"cell_type":"markdown","source":"<img src=\"https://slidetodoc.com/presentation_image_h/2f087c491fa6549a8cb25688253dec9b/image-14.jpg\" width=\"650\" align=\"centr\"/>","metadata":{"id":"yKGgmeoSjLbG"}},{"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(x_train, y_train)","metadata":{"id":"yJIBoW2EjNCY","executionInfo":{"status":"ok","timestamp":1649077165744,"user_tz":-120,"elapsed":45,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"c6df6e5b-2070-4c5c-9f64-3d82dfa6f03b","execution":{"iopub.status.busy":"2022-04-07T11:35:17.690895Z","iopub.execute_input":"2022-04-07T11:35:17.691118Z","iopub.status.idle":"2022-04-07T11:35:17.702926Z","shell.execute_reply.started":"2022-04-07T11:35:17.691092Z","shell.execute_reply":"2022-04-07T11:35:17.702167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","metadata":{"id":"NfrNxb3ZjNJS","executionInfo":{"status":"ok","timestamp":1649077165745,"user_tz":-120,"elapsed":41,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"45c3b310-6086-43bd-fce3-5de5b2f519c9","execution":{"iopub.status.busy":"2022-04-07T11:35:17.980882Z","iopub.execute_input":"2022-04-07T11:35:17.981097Z","iopub.status.idle":"2022-04-07T11:35:17.991248Z","shell.execute_reply.started":"2022-04-07T11:35:17.981072Z","shell.execute_reply":"2022-04-07T11:35:17.990111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_c_dtc\"></a>\n### 3.2.6. Desicion tree classification","metadata":{"id":"vBOqkCBtqN5E"}},{"cell_type":"markdown","source":"<img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/decision-tree-classification-algorithm2.png\" width=\"650\" align=\"centr\"/>","metadata":{"id":"qR-4qXx4s3Q9"}},{"cell_type":"markdown","source":"Weak against overfitting, use random forest to prevent that, if that is the case","metadata":{"id":"eDdWlRWEtLvC"}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(x_train, y_train)","metadata":{"id":"NCLkXhFPs928","executionInfo":{"status":"ok","timestamp":1649077165746,"user_tz":-120,"elapsed":37,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"779090e7-bc68-4347-a697-3f23491fcd56","execution":{"iopub.status.busy":"2022-04-07T11:35:18.278991Z","iopub.execute_input":"2022-04-07T11:35:18.279348Z","iopub.status.idle":"2022-04-07T11:35:18.290198Z","shell.execute_reply.started":"2022-04-07T11:35:18.279285Z","shell.execute_reply":"2022-04-07T11:35:18.289518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","metadata":{"id":"KQLRYwpFtIJM","executionInfo":{"status":"ok","timestamp":1649077166182,"user_tz":-120,"elapsed":466,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"fe9b6e9d-03f3-4c0e-8702-c49612ee7d8d","execution":{"iopub.status.busy":"2022-04-07T11:35:18.574442Z","iopub.execute_input":"2022-04-07T11:35:18.574673Z","iopub.status.idle":"2022-04-07T11:35:18.584274Z","shell.execute_reply.started":"2022-04-07T11:35:18.574647Z","shell.execute_reply":"2022-04-07T11:35:18.583359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_c_rfc\"></a>\n### 3.2.7. Random forest classification","metadata":{"id":"vu8C9jOpteuc"}},{"cell_type":"markdown","source":"<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/76/Random_forest_diagram_complete.png\" width=\"650\" align=\"centr\"/>","metadata":{"id":"fQngreGVtg2a"}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier.fit(x_train, y_train)","metadata":{"id":"-AzIgb6UtqR_","executionInfo":{"status":"ok","timestamp":1649077166183,"user_tz":-120,"elapsed":39,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"5e47d2b5-70c3-40db-d4a1-6db504438d8a","execution":{"iopub.status.busy":"2022-04-07T11:35:18.867836Z","iopub.execute_input":"2022-04-07T11:35:18.868054Z","iopub.status.idle":"2022-04-07T11:35:18.893735Z","shell.execute_reply.started":"2022-04-07T11:35:18.868029Z","shell.execute_reply":"2022-04-07T11:35:18.893029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","metadata":{"id":"ClpbxxI6tqtb","executionInfo":{"status":"ok","timestamp":1649077166184,"user_tz":-120,"elapsed":35,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"1ef57784-3e39-447b-b84c-938473f4a664","execution":{"iopub.status.busy":"2022-04-07T11:35:19.161043Z","iopub.execute_input":"2022-04-07T11:35:19.162003Z","iopub.status.idle":"2022-04-07T11:35:19.176859Z","shell.execute_reply.started":"2022-04-07T11:35:19.161955Z","shell.execute_reply":"2022-04-07T11:35:19.176179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_c_lgbm\"></a>\n### 3.2.8. LightLGBM model","metadata":{"id":"UC5f9XmduTJI"}},{"cell_type":"markdown","source":"<img src=\"https://miro.medium.com/max/3000/1*AZsSoXb8lc5N6mnhqX5JCg.png\" width=\"650\" align=\"centr\"/>\n<img src=\"https://miro.medium.com/max/3000/1*whSa8rY4sgFQj1rEcWr8Ag.png\" width=\"650\" align=\"centr\"/>","metadata":{"id":"LxWSwUyWubBt"}},{"cell_type":"markdown","source":"Light GBM is a gradient boosting framework that uses tree based learning algorithm.\n\nLight GBM grows tree vertically while other algorithm grows trees horizontally meaning that Light GBM grows tree leaf-wise while other algorithm grows level-wise. It will choose the leaf with max delta loss to grow. When growing the same leaf, Leaf-wise algorithm can reduce more loss than a level-wise algorithm.\n\nWhy is it good? \n\n\n\n*   High speed\n*   Can handle large datasets\n*   low memory use\n*   supports gpu learning\n\n","metadata":{"id":"FvDc87sAuoyz"}},{"cell_type":"code","source":"import lightgbm as lgb\n\n# params still need to be optimized\nparams = {}\nparams['learning_rate'] = 0.003\nparams['boosting_type'] = 'gbdt'\nparams['objective'] = 'binary'\nparams['metric'] = 'binary_logloss'\nparams['sub_feature'] = 0.5\nparams['num_leaves'] = 10\nparams['min_data'] = 50\nparams['max_depth'] = 10\n\nclassifier_lgb = lgb.LGBMClassifier(**params)\nclf = classifier_lgb.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:35:19.456624Z","iopub.execute_input":"2022-04-07T11:35:19.456845Z","iopub.status.idle":"2022-04-07T11:35:21.552261Z","shell.execute_reply.started":"2022-04-07T11:35:19.456819Z","shell.execute_reply":"2022-04-07T11:35:21.551698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = clf.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","metadata":{"id":"cnd7XnDmEFl1","executionInfo":{"status":"ok","timestamp":1649077166188,"user_tz":-120,"elapsed":30,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"055122e8-fcdd-4939-8ade-c50d53ee2d0b","execution":{"iopub.status.busy":"2022-04-07T11:35:21.555644Z","iopub.execute_input":"2022-04-07T11:35:21.55711Z","iopub.status.idle":"2022-04-07T11:35:21.571361Z","shell.execute_reply.started":"2022-04-07T11:35:21.557076Z","shell.execute_reply":"2022-04-07T11:35:21.570714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some extra explanation on the parameters if needed:\nhttps://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc","metadata":{"id":"-rwA3fZ5Guv9"}},{"cell_type":"markdown","source":"<a id=\"cell-basic_c_xgbm\"></a>\n### 3.2.9. XGBoost","metadata":{"id":"Ts70YU9TG53i"}},{"cell_type":"markdown","source":"<img src=\"https://www.researchgate.net/profile/Li-Mingtao-2/publication/335483097/figure/fig3/AS:934217085100032@1599746118459/A-general-architecture-of-XGBoost.ppm\" width=\"650\" align=\"centr\"/>","metadata":{"id":"XPxT6zZUZftZ"}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nimport warnings # ignoring some warning here. I have to update the xgb code to no longer send deprecated warnings \nwarnings.filterwarnings('ignore')\n\nclassifier = XGBClassifier(use_label_encoder=True,eval_metric='logloss')\nclassifier.fit(x_train, y_train)","metadata":{"id":"CKjsoBIEZvze","executionInfo":{"status":"ok","timestamp":1649077166189,"user_tz":-120,"elapsed":26,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"9f606628-a403-4caa-874a-32e9eb4ce0f6","execution":{"iopub.status.busy":"2022-04-07T11:35:21.572543Z","iopub.execute_input":"2022-04-07T11:35:21.573057Z","iopub.status.idle":"2022-04-07T11:35:22.9777Z","shell.execute_reply.started":"2022-04-07T11:35:21.572962Z","shell.execute_reply":"2022-04-07T11:35:22.976843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","metadata":{"id":"qkNoafKeZwI7","executionInfo":{"status":"ok","timestamp":1649077166190,"user_tz":-120,"elapsed":21,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"7544a71c-8e09-4184-ec9b-4e5e8e3f3ef6","execution":{"iopub.status.busy":"2022-04-07T11:35:22.979677Z","iopub.execute_input":"2022-04-07T11:35:22.980344Z","iopub.status.idle":"2022-04-07T11:35:22.993864Z","shell.execute_reply.started":"2022-04-07T11:35:22.980279Z","shell.execute_reply":"2022-04-07T11:35:22.993344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\n\n\naccuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))","metadata":{"id":"TpwkmX_jk1iC","executionInfo":{"status":"ok","timestamp":1649077166568,"user_tz":-120,"elapsed":393,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"062aaf74-dbdf-462f-dc4e-a3194c3bd301","execution":{"iopub.status.busy":"2022-04-07T11:35:22.994684Z","iopub.execute_input":"2022-04-07T11:35:22.996413Z","iopub.status.idle":"2022-04-07T11:35:23.436818Z","shell.execute_reply.started":"2022-04-07T11:35:22.99638Z","shell.execute_reply":"2022-04-07T11:35:23.436295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-basic_c_cbm\"></a>\n### 3.2.10. CatBoost","metadata":{"id":"fvW1uYCHmv2m"}},{"cell_type":"markdown","source":"<img src=\"https://miro.medium.com/max/875/1*E006sjlIjabDJ3jNixRSnA.png\" width=\"650\" align=\"centr\"/>\n\nsource: https://medium.com/riskified-technology/xgboost-lightgbm-or-catboost-which-boosting-algorithm-should-i-use-e7fda7bb36bc\n\n<img src=\"https://i1.wp.com/thaddeus-segura.com/wp-content/uploads/2020/10/cb9.png?resize=923%2C262&ssl=1\" width=\"650\" align=\"centr\"/>","metadata":{"id":"c7PeR-fGmwCI"}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nclassifier = CatBoostClassifier()\nclassifier.fit(x_train, y_train, logging_level='Silent')","metadata":{"id":"jEAprDSzmwcW","executionInfo":{"status":"ok","timestamp":1649077180090,"user_tz":-120,"elapsed":1331,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"251f3406-394f-493a-cb9e-aa20a14010e9","execution":{"iopub.status.busy":"2022-04-07T11:35:23.439812Z","iopub.execute_input":"2022-04-07T11:35:23.440487Z","iopub.status.idle":"2022-04-07T11:35:24.408203Z","shell.execute_reply.started":"2022-04-07T11:35:23.44045Z","shell.execute_reply":"2022-04-07T11:35:24.407517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","metadata":{"id":"yrIx5HDupa18","executionInfo":{"status":"ok","timestamp":1649077180466,"user_tz":-120,"elapsed":382,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"38292fb3-eee1-460f-dc80-bf40991f4b19","execution":{"iopub.status.busy":"2022-04-07T11:35:24.409368Z","iopub.execute_input":"2022-04-07T11:35:24.409762Z","iopub.status.idle":"2022-04-07T11:35:24.422326Z","shell.execute_reply.started":"2022-04-07T11:35:24.409722Z","shell.execute_reply":"2022-04-07T11:35:24.421357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-nn\"></a>\n## 3.3 Neural Networks (NN)","metadata":{"id":"yWejtO4v9txU"}},{"cell_type":"markdown","source":"<a id=\"cell-nn_data\"></a>\n### Importing Simple Data","metadata":{"id":"qO0MQ0AO-IGs"}},{"cell_type":"markdown","source":"This dataset is a classification problem, so we will have to Encode the dataset using the OneHotEncoder.","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/white-wine-quality/winequality-white.csv', sep=';')\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:35:24.423819Z","iopub.execute_input":"2022-04-07T11:35:24.424125Z","iopub.status.idle":"2022-04-07T11:35:24.46249Z","shell.execute_reply.started":"2022-04-07T11:35:24.42409Z","shell.execute_reply":"2022-04-07T11:35:24.461793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting the features(x) with the expected result(y) (quality of wine)\nx = data.iloc[:, :-1].values\ny = data.iloc[:, -1].values","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:35:24.463904Z","iopub.execute_input":"2022-04-07T11:35:24.464375Z","iopub.status.idle":"2022-04-07T11:35:24.472143Z","shell.execute_reply.started":"2022-04-07T11:35:24.464338Z","shell.execute_reply":"2022-04-07T11:35:24.471425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder()\ny = ohe.fit_transform(y.reshape(-1,1)).toarray()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:35:24.475639Z","iopub.execute_input":"2022-04-07T11:35:24.475906Z","iopub.status.idle":"2022-04-07T11:35:24.483406Z","shell.execute_reply.started":"2022-04-07T11:35:24.47587Z","shell.execute_reply":"2022-04-07T11:35:24.482662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=555)\n\nprint(\"Unscaled training data example:\" + np.array2string(x_train[0], formatter={'float_kind':lambda x: \"%.0f\" % x}))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:35:24.484648Z","iopub.execute_input":"2022-04-07T11:35:24.485009Z","iopub.status.idle":"2022-04-07T11:35:24.493176Z","shell.execute_reply.started":"2022-04-07T11:35:24.484972Z","shell.execute_reply":"2022-04-07T11:35:24.492505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n# saving unscaled versions for testing purposes if needed\nunscaled_x_train = x_train\nunscaled_x_test = x_test\n\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)\n\nprint(\"Scaled training data example:\" + np.array2string(x_train[0], formatter={'float_kind':lambda x: \"%.3f\" % x}))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:35:24.494548Z","iopub.execute_input":"2022-04-07T11:35:24.494998Z","iopub.status.idle":"2022-04-07T11:35:24.504724Z","shell.execute_reply.started":"2022-04-07T11:35:24.494962Z","shell.execute_reply":"2022-04-07T11:35:24.503957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-nn_seq\"></a>\n### 3.3.1 Neural Network: Sequential() keras","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://nickmccullum.com/images/python-deep-learning/how-do-neural-networks-really-work/completed-neural-network.png\" width=\"650\" align=\"centr\"/>","metadata":{}},{"cell_type":"markdown","source":"This code snipet contains a simple sequential keras model. It can be used for simple models which only have one input and output. Otherwise you should use functional keras API.\n\nActivation functions commonly used:\n\n<img src=\"https://www.researchgate.net/profile/Aaron-Stebner-2/publication/341310767/figure/fig7/AS:890211844255749@1589254451431/Common-activation-functions-in-artificial-neural-networks-NNs-that-introduce.ppm\" width=\"650\" align=\"centr\"/>\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Dense, BatchNormalization\n\nBATCH_SIZE = 32\nVAL_SPLIT = 0.1\nEPOCH_NUM = 15\nLEARNING_RATE = 0.0002\n\nmodel = Sequential()\n\nmodel.add(Dense(units = 32, activation = 'relu', input_dim = 11))\nmodel.add(Dense(units=64,activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(units=64,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(units=64,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(units=32,activation='relu'))\nmodel.add(Dense(units=7,activation='softmax'))\n\nopt = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\nmodel.compile(optimizer= opt, loss='categorical_crossentropy',metrics=['accuracy'])\n\nfitted_model= model.fit(x_train, y_train, validation_split= VAL_SPLIT, epochs= EPOCH_NUM, batch_size= BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:35:24.506071Z","iopub.execute_input":"2022-04-07T11:35:24.506475Z","iopub.status.idle":"2022-04-07T11:35:44.999741Z","shell.execute_reply.started":"2022-04-07T11:35:24.506441Z","shell.execute_reply":"2022-04-07T11:35:44.99898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\ntf.keras.utils.plot_model(model,  show_shapes=True,expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:35:45.001443Z","iopub.execute_input":"2022-04-07T11:35:45.001695Z","iopub.status.idle":"2022-04-07T11:35:45.847794Z","shell.execute_reply.started":"2022-04-07T11:35:45.001666Z","shell.execute_reply":"2022-04-07T11:35:45.846979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analysis on Training the model:\n\nIf your training (blue line) starts to heavily outperform the validation (yellow line), then you are overfitting. Solutions against this:\n\n* Change learning rate higher/lower OR change it to a decaying learning rate\n* Regularize your model by using BatchNormalization and or Dropout\n* Data Engineer your dataset, to become more robust (example: binning)\n* Make the neural network smaller\n\nDeciding how big your neural network should be:\n\n* Make your neural network bigger as long as it does not overfit the data on Val/Test-dataset\n* The more data you have, the bigger your model can become without overfitting\n* Don't make too big of a NN if you don't have a lot of data. Example: having 1k dataset but 1million parameters in the model will almost always create a bad model. But it is normal that you have more parameters than data samples, just don't go overboard and start thinking about regularization if it does get out of hand. Regularization helps a lot with bigger models.","metadata":{}},{"cell_type":"code","source":"def plot_metrics(history):\n  metrics = ['loss', 'accuracy']\n  for n, metric in enumerate(metrics):\n    try:\n      name = metric.replace(\"_\",\" \").capitalize()\n      plt.plot(history.epoch, history.history[metric], label='Train')\n      plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n      plt.xlabel('Epoch')\n      plt.ylabel(name)\n      if metric == 'loss':\n        plt.ylim([0, plt.ylim()[1]])\n      elif metric == 'auc':\n        plt.ylim([0.8,1])\n      else:\n        plt.ylim([0,1])\n      plt.legend()\n      plt.show()  \n    except:\n      pass\nplot_metrics(model.history)\n\nplt.title(label='Zoomed in Accuracy plot')\nplt.plot(fitted_model.history[\"accuracy\"],label='Train')\nplt.plot(fitted_model.history[\"val_accuracy\"],linestyle=\"--\",label='Validation')\nplt.legend()\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:35:45.849438Z","iopub.execute_input":"2022-04-07T11:35:45.849798Z","iopub.status.idle":"2022-04-07T11:35:46.441804Z","shell.execute_reply.started":"2022-04-07T11:35:45.849759Z","shell.execute_reply":"2022-04-07T11:35:46.441124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Post processing for this specific dataset. This might be different for a case by case basis.","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(x_test)\n\npred = list()\nfor i in range(len(y_pred)):\n  pred.append(np.argmax(y_pred[i]))\n\ntest = list()\nfor i in range(len(y_test)):\n  test.append(np.argmax(y_test[i]))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:35:46.443227Z","iopub.execute_input":"2022-04-07T11:35:46.443709Z","iopub.status.idle":"2022-04-07T11:35:46.626719Z","shell.execute_reply.started":"2022-04-07T11:35:46.443671Z","shell.execute_reply":"2022-04-07T11:35:46.625977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analysis of the result","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(test, pred)\nprint(cm)\nprint(accuracy_score(test, pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:35:46.627949Z","iopub.execute_input":"2022-04-07T11:35:46.628215Z","iopub.status.idle":"2022-04-07T11:35:46.638272Z","shell.execute_reply.started":"2022-04-07T11:35:46.62818Z","shell.execute_reply":"2022-04-07T11:35:46.637341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nreport = classification_report(test,pred)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:35:46.63948Z","iopub.execute_input":"2022-04-07T11:35:46.639985Z","iopub.status.idle":"2022-04-07T11:35:46.652826Z","shell.execute_reply.started":"2022-04-07T11:35:46.639943Z","shell.execute_reply":"2022-04-07T11:35:46.652047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-nn_func\"></a>\n### 3.3.2 Neural Network: Functional Keras","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://www.researchgate.net/publication/330230427/figure/fig5/AS:962670173892631@1606529863497/A-multi-layer-neural-network-with-n-inputs-at-least-two-hidden-layers-and-one-output.png\" width=\"650\" align=\"centr\"/>","metadata":{}},{"cell_type":"markdown","source":"You should use Functional keras if you have more complex models with multiple inputs and outputs. I will use an example which was widely used during the https://www.kaggle.com/competitions/ubiquant-market-prediction competition where 1 feature had it's own model and got merged with the other 300 features later in the model. The reason being, that the 1 feature had a significant meaning to the outcome of the output value. This did not always mean a better performance, but it was a great idea.\n\nI would also recommend using functional keras for complex Convolutional Neural Networks but more on that later.","metadata":{}},{"cell_type":"code","source":"%%time\ntrain_df = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:35:46.656521Z","iopub.execute_input":"2022-04-07T11:35:46.656712Z","iopub.status.idle":"2022-04-07T11:36:09.042032Z","shell.execute_reply.started":"2022-04-07T11:35:46.656684Z","shell.execute_reply":"2022-04-07T11:36:09.040508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# making the dataset smaller for example purposes\ntrain_df = train_df[:250_000]\nimport gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:36:09.043397Z","iopub.execute_input":"2022-04-07T11:36:09.043655Z","iopub.status.idle":"2022-04-07T11:36:09.297428Z","shell.execute_reply.started":"2022-04-07T11:36:09.043619Z","shell.execute_reply":"2022-04-07T11:36:09.296527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Altering previous dataset to fit our model.","metadata":{}},{"cell_type":"code","source":"# Preprocessing the data\ninvestment_id = train_df.pop(\"investment_id\") # splitsing investment_id from the dataset to be fed seperatly into the NN\ninvestment_id_unique = pd.DataFrame(investment_id.unique())\ninvestment_id_unique_size = len(investment_id_unique) + 1\n\ntrain_df.pop(\"time_id\") # deleting the time_id row\ny = train_df.pop(\"target\")\n\nn_features = 300\nfeatures = [f'f_{i}' for i in range(n_features)]","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:36:09.299032Z","iopub.execute_input":"2022-04-07T11:36:09.299324Z","iopub.status.idle":"2022-04-07T11:36:09.326716Z","shell.execute_reply.started":"2022-04-07T11:36:09.29926Z","shell.execute_reply":"2022-04-07T11:36:09.326049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.layers import Dropout, Dense, BatchNormalization\n\nBATCH_SIZE = 64\nVAL_SPLIT = 0.1\nEPOCH_NUM = 3\nLEARNING_RATE = 0.001\n\n# Defining the input size\ninvestment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\nfeatures_inputs = tf.keras.Input((300, ), dtype=tf.float16)\n\n# Encoding the investment_id within the Neural Net, this is not always necessary based what kind of data you have\ninvestment_id_lookup_layer = layers.IntegerLookup(max_tokens=investment_id_unique_size)\ninvestment_id_lookup_layer.adapt(investment_id_unique)\n\n# Defining the model of investment_id\ninvestment_id_x = investment_id_lookup_layer(investment_id_inputs)\ninvestment_id_x = layers.Embedding(investment_id_unique_size, 32, input_length=1)(investment_id_x)\ninvestment_id_x = layers.Reshape((-1, ))(investment_id_x) # Reshaping the model into the right dimensions after the embedding\ninvestment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\ninvestment_id_x = layers.BatchNormalization()(investment_id_x)\ninvestment_id_x = layers.Dense(32, activation='swish')(investment_id_x)\n\n# Defining the model for all other features\nfeature_x = layers.Dense(256, activation='swish')(features_inputs)\nfeature_x = layers.Dense(256, activation='swish')(feature_x)\nfeature_x = layers.BatchNormalization()(feature_x)\nfeature_x = layers.Dense(128, activation='swish')(feature_x)\nfeature_x = layers.Dropout(0.25)(feature_x)\n\n# Merging the 2 models into one\nx = layers.Concatenate(axis=1)([investment_id_x, feature_x])\nx = layers.Dense(64, activation='swish', kernel_regularizer=\"l2\")(x)\nx = layers.Dropout(0.2)(x)\nx = layers.Dense(32, activation='swish', kernel_regularizer=\"l2\")(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dense(16, activation='swish', kernel_regularizer=\"l2\")(x)\n\noutput = layers.Dense(1)(x)\n\nmodel = tf.keras.Model(inputs=[investment_id_inputs, features_inputs], outputs=[output])\nmodel.compile(optimizer=tf.optimizers.Adam(LEARNING_RATE), loss='mse', metrics='mse')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:36:09.328029Z","iopub.execute_input":"2022-04-07T11:36:09.328506Z","iopub.status.idle":"2022-04-07T11:36:09.6618Z","shell.execute_reply.started":"2022-04-07T11:36:09.328469Z","shell.execute_reply":"2022-04-07T11:36:09.661094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\ntf.keras.utils.plot_model(model,  show_shapes=True,expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:36:09.662932Z","iopub.execute_input":"2022-04-07T11:36:09.663165Z","iopub.status.idle":"2022-04-07T11:36:09.959934Z","shell.execute_reply.started":"2022-04-07T11:36:09.663134Z","shell.execute_reply":"2022-04-07T11:36:09.959191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/gpu:0'):# if no GPU is found it will run with the CPU\n    model.fit([investment_id, train_df], y, validation_split= VAL_SPLIT, epochs = EPOCH_NUM, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:36:09.961575Z","iopub.execute_input":"2022-04-07T11:36:09.962341Z","iopub.status.idle":"2022-04-07T11:37:33.5758Z","shell.execute_reply.started":"2022-04-07T11:36:09.96229Z","shell.execute_reply":"2022-04-07T11:37:33.574969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(history):\n  metrics = ['loss', 'mse']\n  for n, metric in enumerate(metrics):\n    try:\n      name = metric.replace(\"_\",\" \").capitalize()\n      plt.plot(history.epoch, history.history[metric], label='Train')\n      plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n      plt.xlabel('Epoch')\n      plt.ylabel(name)\n      if metric == 'loss':\n        plt.ylim([0, plt.ylim()[1]])\n      elif metric == 'auc':\n        plt.ylim([0.8,1])\n      else:\n        plt.ylim([0,1])\n      plt.legend()\n      plt.show()  \n    except:\n      pass\nplot_metrics(model.history)\n\nplt.title(label='Zoomed in Mse plot')\nplt.plot(model.history.history[\"mse\"],label='Train')\nplt.plot(model.history.history[\"val_mse\"],linestyle=\"--\",label='Validation')\nplt.legend()\nplt.ylabel('Mse')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:37:33.577674Z","iopub.execute_input":"2022-04-07T11:37:33.57795Z","iopub.status.idle":"2022-04-07T11:37:34.157919Z","shell.execute_reply.started":"2022-04-07T11:37:33.577914Z","shell.execute_reply":"2022-04-07T11:37:34.15711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cleaning up RAM\nimport gc\n\ndel train_df\ndel y\ndel investment_id\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-cnn\"></a>\n## 3.4 Convolutional Neural Networks (CNN)","metadata":{"id":"niCnRLTG-RXn"}},{"cell_type":"markdown","source":"<a id=\"cell-cnn_data\"></a>\n### Importing Simple Data","metadata":{"id":"Aqis8K9H-XP6"}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\n\ntrain_data_dir= '../input/rearranged-brain-tumor-dataset-from-ahmed-hamada/DataSet'\ntest_data_dir= '../input/rearranged-brain-tumor-dataset-from-ahmed-hamada/TestDataSet'\n\nIMG_WIDTH = 180\nIMG_HEIGHT = 180\nBATCH_SIZE = 32\n\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        horizontal_flip=True,\n        validation_split=0.2)\n\ntraining_set = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(IMG_WIDTH, IMG_HEIGHT),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='training') # set as training data\n\n\n\nvalidation_datagen = ImageDataGenerator(\n        rescale=1./255,\n        validation_split=0.2)\n\n# Based on example code of keras data preprocessing api doc and Salik Hussaini example code#\nvalidation_set = validation_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(IMG_WIDTH, IMG_HEIGHT),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='validation')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:37:34.159353Z","iopub.execute_input":"2022-04-07T11:37:34.159596Z","iopub.status.idle":"2022-04-07T11:37:35.690986Z","shell.execute_reply.started":"2022-04-07T11:37:34.159561Z","shell.execute_reply":"2022-04-07T11:37:35.690323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-cnn_seq\"></a>\n## 3.4.1 Convolutional Neural Networks: Sequential() keras","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://miro.medium.com/max/1400/1*vkQ0hXDaQv57sALXAJquxA.jpeg\" width=\"650\" align=\"centr\"/>","metadata":{}},{"cell_type":"markdown","source":"**Convolution:** Is applying a filter on an image to capture for example \"edges\" or \"patterns\" of images. These filters can be set but are often parameters and trained by the model.\n\n<img src=\"https://1.cms.s81c.com/sites/default/files/2021-01-06/ICLH_Diagram_Batch_02_17A-ConvolutionalNeuralNetworks-WHITEBG.png\" width=\"650\" align=\"centr\"/>","metadata":{}},{"cell_type":"markdown","source":"**Padding:** Padding is making the previous image/input bigger by adding n-\"empty blocks\" around the image/input. This allows our convolution or pooling to capture edges better. If people use \"same\"-padding. They choose a specific amount of n-\"empty blocks\" to add, which would generate the same dimension of output after convolving/pooling as they had received as input.\n\n<img src=\"https://miro.medium.com/max/666/1*noYcUAa_P8nRilg3Lt_nuA.png\" width=\"650\" align=\"centr\"/>","metadata":{}},{"cell_type":"markdown","source":"**Stride:** The speed at which your filter/pooling goes through your image/input. If they say: Stride=2. This means that you would go 2 steps to the right every filter/pooling instead of 1 step.\n**Pooling:** There are 2 commen pooling methods:\n\n* Max pooling: Take the maximum of an element within that pool matrix\n* Average pooling: Average over all the elements within that pool matrix\n\n<img src=\"https://miro.medium.com/max/1192/1*KQIEqhxzICU7thjaQBfPBQ.png\" width=\"650\" align=\"centr\"/>","metadata":{}},{"cell_type":"markdown","source":"There is a trend to lower the dimensions of the image throughout the CNN and increase the amount of filters throughout the model. This is based on LeNet-5's research paper but I am not qualified to say if this is usefull or good in all CNN problems.\n\n<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2021/03/Screenshot-from-2021-03-18-12-52-17.png\" width=\"650\" align=\"centr\"/>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Dense, BatchNormalization, Conv2D, Flatten, MaxPool2D\n\nBATCH_SIZE = 64\nVAL_SPLIT = 0.1\nEPOCH_NUM = 5\nLEARNING_RATE = 0.001\nIMG_WIDTH = 180\nIMG_HEIGHT = 180\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[IMG_WIDTH, IMG_HEIGHT,3]))\nmodel.add(MaxPool2D(pool_size=2,strides=2))\nmodel.add(Conv2D(filters=32,kernel_size=3,activation='relu'))\nmodel.add(MaxPool2D(pool_size=2,strides=2))\nmodel.add(Flatten())\n\nmodel.add(Dense(units=300,activation='relu'))\nmodel.add(Dense(units=1,activation='sigmoid'))\n\nmodel.compile(optimizer=tf.optimizers.Adam(LEARNING_RATE) ,loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:37:35.692481Z","iopub.execute_input":"2022-04-07T11:37:35.692734Z","iopub.status.idle":"2022-04-07T11:37:35.752501Z","shell.execute_reply.started":"2022-04-07T11:37:35.692699Z","shell.execute_reply":"2022-04-07T11:37:35.75185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\ntf.keras.utils.plot_model(model,  show_shapes=True,expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:37:35.753498Z","iopub.execute_input":"2022-04-07T11:37:35.75372Z","iopub.status.idle":"2022-04-07T11:37:35.990911Z","shell.execute_reply.started":"2022-04-07T11:37:35.753686Z","shell.execute_reply":"2022-04-07T11:37:35.990163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/gpu:0'):# if no GPU is found it will run with the CPU\n    history = model.fit(x = training_set, validation_data=validation_set, epochs = EPOCH_NUM, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:37:35.992891Z","iopub.execute_input":"2022-04-07T11:37:35.993404Z","iopub.status.idle":"2022-04-07T11:38:33.782197Z","shell.execute_reply.started":"2022-04-07T11:37:35.993364Z","shell.execute_reply":"2022-04-07T11:38:33.781477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluating the model","metadata":{}},{"cell_type":"code","source":"def plot_metrics(history):\n  metrics = ['loss', 'accuracy']\n  for n, metric in enumerate(metrics):\n    try:\n      name = metric.replace(\"_\",\" \").capitalize()\n      plt.plot(history.epoch, history.history[metric], label='Train')\n      plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n      plt.xlabel('Epoch')\n      plt.ylabel(name)\n      if metric == 'loss':\n        plt.ylim([0, plt.ylim()[1]])\n      elif metric == 'auc':\n        plt.ylim([0.8,1])\n      else:\n        plt.ylim([0,1])\n      plt.legend()\n      plt.show()  \n    except:\n      pass\nplot_metrics(model.history)\n\nplt.title(label='Zoomed in Accuracy plot')\nplt.plot(history.history[\"accuracy\"],label='Train')\nplt.plot(history.history[\"val_accuracy\"],linestyle=\"--\",label='Validation')\nplt.legend()\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:38:33.78363Z","iopub.execute_input":"2022-04-07T11:38:33.783968Z","iopub.status.idle":"2022-04-07T11:38:34.364459Z","shell.execute_reply.started":"2022-04-07T11:38:33.783928Z","shell.execute_reply":"2022-04-07T11:38:34.363774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from os import listdir\nfrom os.path import isfile, join\n\ntest_labels = listdir(test_data_dir)\ntest_image_array= []\nnumber_of_files= 0.\nprediction_accuracy= 0\n\nfor folder_number in range(len(test_labels)):\n  for path in listdir(test_data_dir+'/'+test_labels[folder_number]):\n    number_of_files+=1\n\n    test_image= image.load_img(path=test_data_dir+'/'+test_labels[folder_number]+'/'+path,target_size=(IMG_WIDTH,IMG_HEIGHT))\n    test_image= image.img_to_array(test_image)\n\n    normalized_test_image = test_image*1./255\n\n    test_image= np.expand_dims(normalized_test_image,axis=0)\n    prediction= model.predict(test_image)\n    #changing the prediction \"numbers\" to classnames\n    if prediction >= 0.5:\n      prediction= 'yes'\n    else:\n      prediction= 'no'\n    if prediction == test_labels[folder_number]:\n      prediction_accuracy+=1\n\nprediction_accuracy= prediction_accuracy/number_of_files\n\nprint('prediction accuracy= '+ str(prediction_accuracy*100)+'%')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:38:34.365789Z","iopub.execute_input":"2022-04-07T11:38:34.36606Z","iopub.status.idle":"2022-04-07T11:38:48.822677Z","shell.execute_reply.started":"2022-04-07T11:38:34.366025Z","shell.execute_reply":"2022-04-07T11:38:48.821871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-cnn_func\"></a>\n## 3.4.2 Convolutional Neural Networks: Functional keras","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.layers import Dropout, Dense, BatchNormalization, Conv2D, Flatten, MaxPool2D\n\nBATCH_SIZE = 64\nVAL_SPLIT = 0.1\nEPOCH_NUM = 5\nLEARNING_RATE = 0.001\nIMG_WIDTH = 180\nIMG_HEIGHT = 180\n\n# Defining the input size\nx_inputs = tf.keras.Input((IMG_WIDTH, IMG_HEIGHT,3))\n\nZ1 = layers.Conv2D(filters = 32 , kernel_size= (3,3), padding='same')(x_inputs)\nA1 = layers.ReLU()(Z1)\nP1 = layers.MaxPool2D(pool_size = (2,2), strides= (2,2), padding='valid')(A1)\nZ2 = layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = 1)(P1)\nA2 = layers.ReLU()(Z2)\nP2 = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(A2)\nF = layers.Flatten()(P2)\n\nZ3 = tf.keras.layers.Dense(units=300, activation='relu')(F)\noutputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(Z3)\n\nmodel = tf.keras.Model(inputs=x_inputs, outputs=outputs)\nmodel.compile(optimizer=tf.optimizers.Adam(LEARNING_RATE) ,loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:38:48.824292Z","iopub.execute_input":"2022-04-07T11:38:48.824566Z","iopub.status.idle":"2022-04-07T11:38:48.879944Z","shell.execute_reply.started":"2022-04-07T11:38:48.824528Z","shell.execute_reply":"2022-04-07T11:38:48.879264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\ntf.keras.utils.plot_model(model,  show_shapes=True,expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:38:48.881019Z","iopub.execute_input":"2022-04-07T11:38:48.881351Z","iopub.status.idle":"2022-04-07T11:38:49.156473Z","shell.execute_reply.started":"2022-04-07T11:38:48.881313Z","shell.execute_reply":"2022-04-07T11:38:49.155361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/gpu:0'):# if no GPU is found it will run with the CPU\n    history = model.fit(x = training_set, validation_data=validation_set, epochs = EPOCH_NUM, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:38:49.158415Z","iopub.execute_input":"2022-04-07T11:38:49.15943Z","iopub.status.idle":"2022-04-07T11:39:32.756921Z","shell.execute_reply.started":"2022-04-07T11:38:49.159391Z","shell.execute_reply":"2022-04-07T11:39:32.755969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(history):\n  metrics = ['loss', 'accuracy']\n  for n, metric in enumerate(metrics):\n    try:\n      name = metric.replace(\"_\",\" \").capitalize()\n      plt.plot(history.epoch, history.history[metric], label='Train')\n      plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n      plt.xlabel('Epoch')\n      plt.ylabel(name)\n      if metric == 'loss':\n        plt.ylim([0, plt.ylim()[1]])\n      elif metric == 'auc':\n        plt.ylim([0.8,1])\n      else:\n        plt.ylim([0,1])\n      plt.legend()\n      plt.show()  \n    except:\n      pass\nplot_metrics(model.history)\n\nplt.title(label='Zoomed in Accuracy plot')\nplt.plot(history.history[\"accuracy\"],label='Train')\nplt.plot(history.history[\"val_accuracy\"],linestyle=\"--\",label='Validation')\nplt.legend()\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:39:32.75903Z","iopub.execute_input":"2022-04-07T11:39:32.759325Z","iopub.status.idle":"2022-04-07T11:39:33.380901Z","shell.execute_reply.started":"2022-04-07T11:39:32.759263Z","shell.execute_reply":"2022-04-07T11:39:33.380143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-cnn_skip\"></a>\n## 3.4.3 Skip Connections/Residual blocks","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://miro.medium.com/max/1140/1*D0F3UitQ2l5Q0Ak-tjEdJg.png\" width=\"650\" align=\"centr\"/>\n\n<img src=\"https://theaisummer.com/static/2c373d3667071700748bf451c4e62b78/3accd/long-skip-connection.jpg\" width=\"650\" align=\"centr\"/>\n\nSkip connections/Residual blocks are used to solve the performance degradation problem associated with deep neural architectures. (This solution was introduced with the ResNet paper) See graph below to show the problem that it will prevent.\n\n<img src=\"https://miro.medium.com/max/1280/1*Ku0ChYxemQyF1hz348ExVA.png\" width=\"650\" align=\"centr\"/>","metadata":{}},{"cell_type":"markdown","source":"It can sometimes be usefull to make an **Identity Block** method mentioned in the ResNet paper to easily make a 2-layer/3-layer skip. In an identy block, your input dimensions should be te same as the output. However, if this is not the case you can add a conv layer in the skip to compensate this dimension difference. This is called a **Convolution Block**\n\n<img src=\"https://i.stack.imgur.com/37qzA.png\" width=\"650\" align=\"centr\"/>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.layers import Dropout, Dense, BatchNormalization, Conv2D, Flatten, MaxPool2D, Activation, Add\n\nBATCH_SIZE = 32\nVAL_SPLIT = 0.1\nEPOCH_NUM = 5\nLEARNING_RATE = 0.001\nIMG_WIDTH = 180\nIMG_HEIGHT = 180\n\n\n# Defining the input size\nx_inputs = tf.keras.Input((IMG_WIDTH, IMG_HEIGHT,3))\n\nX = Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding='same')(x_inputs)\nX = BatchNormalization(axis = 3)(X) # Default axis\nX = Activation('relu')(X)\nX = MaxPool2D(pool_size = (2,2), strides= (2,2), padding='same')(X)\n\n# Save the input value. You'll need this later to add back to the main path. \nX_shortcut = X\n\nX = Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding='same')(X)\nX = BatchNormalization(axis = 3)(X) # Default axis\nX = Activation('relu')(X)\n\nX = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same')(X)\nX = BatchNormalization(axis=3)(X)\nX = Activation('relu')(X)\n\nX = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same')(X)\nX = BatchNormalization(axis=3)(X)\n\n# Shortcut\nX = Add()([X, X_shortcut])\nX = Activation('relu')(X)\n\nX = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(X)\nX = layers.Flatten()(X)\n\nX = tf.keras.layers.Dense(units=300, activation='relu')(X)\noutputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(X)\n\nmodel = tf.keras.Model(inputs=x_inputs, outputs=outputs)\nmodel.compile(optimizer=tf.optimizers.Adam(LEARNING_RATE) ,loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:39:33.382286Z","iopub.execute_input":"2022-04-07T11:39:33.382562Z","iopub.status.idle":"2022-04-07T11:39:33.492775Z","shell.execute_reply.started":"2022-04-07T11:39:33.382527Z","shell.execute_reply":"2022-04-07T11:39:33.492147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\ntf.keras.utils.plot_model(model,  show_shapes=True,expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:39:33.494069Z","iopub.execute_input":"2022-04-07T11:39:33.494332Z","iopub.status.idle":"2022-04-07T11:39:34.29376Z","shell.execute_reply.started":"2022-04-07T11:39:33.494273Z","shell.execute_reply":"2022-04-07T11:39:34.290587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/gpu:0'):# if no GPU is found it will run with the CPU\n    history = model.fit(x = training_set, validation_data=validation_set, epochs = EPOCH_NUM, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:39:34.295884Z","iopub.execute_input":"2022-04-07T11:39:34.296358Z","iopub.status.idle":"2022-04-07T11:40:19.433699Z","shell.execute_reply.started":"2022-04-07T11:39:34.296313Z","shell.execute_reply":"2022-04-07T11:40:19.432931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have too little data to justify using this big of a model, hence the worse accuracy result (also the model is pretty bad to be honest). Skip connections/residual blocks should only be used in very deep neural networks. I hope the example code could at least help jumpstart your specific problem.","metadata":{}},{"cell_type":"code","source":"def plot_metrics(history):\n  metrics = ['loss', 'accuracy']\n  for n, metric in enumerate(metrics):\n    try:\n      name = metric.replace(\"_\",\" \").capitalize()\n      plt.plot(history.epoch, history.history[metric], label='Train')\n      plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n      plt.xlabel('Epoch')\n      plt.ylabel(name)\n      if metric == 'loss':\n        plt.ylim([0, plt.ylim()[1]])\n      elif metric == 'auc':\n        plt.ylim([0.8,1])\n      else:\n        plt.ylim([0,1])\n      plt.legend()\n      plt.show()  \n    except:\n      pass\nplot_metrics(model.history)\n\nplt.title(label='Zoomed in Accuracy plot')\nplt.plot(history.history[\"accuracy\"],label='Train')\nplt.plot(history.history[\"val_accuracy\"],linestyle=\"--\",label='Validation')\nplt.legend()\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:40:19.436687Z","iopub.execute_input":"2022-04-07T11:40:19.436928Z","iopub.status.idle":"2022-04-07T11:40:20.017914Z","shell.execute_reply.started":"2022-04-07T11:40:19.436895Z","shell.execute_reply":"2022-04-07T11:40:20.017179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-cnn_incept\"></a>\n### 3.4.4 Inception Network/Network in Network","metadata":{}},{"cell_type":"markdown","source":"Using a 1x1 filter + Activation is usefull to shrink/enlarge the input. This could result in lower computation power. This is used in the inception network to lower the computation power needed before concatenating the different matricis together. The use of a 1x1 Conv is sometimes also referred to a \"**Bottleneck**\".\n\n<img src=\"https://i.ytimg.com/vi/KfV8CJh7hE0/maxresdefault.jpg\" width=\"650\" align=\"centr\"/>\n\n<img src=\"https://miro.medium.com/max/1276/1*qVQbA9GYe5VKIQtAQWPM9w.jpeg\" width=\"650\" align=\"centr\"/>","metadata":{}},{"cell_type":"markdown","source":"The auxiliary classifiers in the GooLeNet help regularize the network and provide extra classifiers which might be usefull in ensemble models.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.layers import Dropout, Dense, BatchNormalization, Conv2D, Flatten, MaxPool2D, Activation, Add, Conv1D\n\nBATCH_SIZE = 32\nVAL_SPLIT = 0.1\nEPOCH_NUM = 5\nLEARNING_RATE = 0.001\nIMG_WIDTH = 180\nIMG_HEIGHT = 180\n\n\n# Defining the input size\nx_inputs = tf.keras.Input((IMG_WIDTH, IMG_HEIGHT,3))\n\nX = Conv2D(filters = 32, kernel_size = (3,3), strides = (2,2))(x_inputs)\nX = BatchNormalization(axis = 3)(X) # Default axis\nX = Activation('relu')(X)\nX = MaxPool2D(pool_size = (2,2), strides= (2,2))(X)\n\nX1 = Conv1D(filters = 5, kernel_size = 1, padding = 'same')(X)\nX1 = Activation('relu')(X1)\n\nX2 = Conv1D(filters = 10, kernel_size = 1, padding = 'same')(X)\nX2 = Activation('relu')(X2)\n\nX3 = Conv1D(filters = 5, kernel_size = 1, padding = 'same')(X)\nX3 = BatchNormalization(axis = 3)(X3) # Default axis\nX3 = Activation('relu')(X3)\nX3 = Conv2D(filters = 15, kernel_size = (3,3), strides = (1,1), padding='same')(X3)\nX3 = BatchNormalization(axis = 3)(X3) # Default axis\nX3 = Activation('relu')(X3)\n\nX4 = Conv1D(filters = 10, kernel_size = 1, padding = 'same')(X)\nX4 = Activation('relu')(X4)\nX4 = MaxPool2D(pool_size = (1,1), strides= (1,1), padding='same')(X4)\n\nX = layers.Concatenate()([X1, X2, X3, X4])\n\nX = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(X)\nX = layers.Flatten()(X)\n\nX = tf.keras.layers.Dense(units=300, activation='relu')(X)\noutputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(X)\n\nmodel = tf.keras.Model(inputs=x_inputs, outputs=outputs)\nmodel.compile(optimizer=tf.optimizers.Adam(LEARNING_RATE) ,loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:40:20.019239Z","iopub.execute_input":"2022-04-07T11:40:20.019496Z","iopub.status.idle":"2022-04-07T11:40:20.186753Z","shell.execute_reply.started":"2022-04-07T11:40:20.019462Z","shell.execute_reply":"2022-04-07T11:40:20.186057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\ntf.keras.utils.plot_model(model,  show_shapes=True,expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:40:20.18804Z","iopub.execute_input":"2022-04-07T11:40:20.188267Z","iopub.status.idle":"2022-04-07T11:40:20.600567Z","shell.execute_reply.started":"2022-04-07T11:40:20.188234Z","shell.execute_reply":"2022-04-07T11:40:20.599767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/gpu:0'):# if no GPU is found it will run with the CPU\n    history = model.fit(x = training_set, validation_data=validation_set, epochs = EPOCH_NUM, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:40:20.607134Z","iopub.execute_input":"2022-04-07T11:40:20.607655Z","iopub.status.idle":"2022-04-07T11:41:06.98714Z","shell.execute_reply.started":"2022-04-07T11:40:20.607616Z","shell.execute_reply":"2022-04-07T11:41:06.986359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(history):\n  metrics = ['loss', 'accuracy']\n  for n, metric in enumerate(metrics):\n    try:\n      name = metric.replace(\"_\",\" \").capitalize()\n      plt.plot(history.epoch, history.history[metric], label='Train')\n      plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n      plt.xlabel('Epoch')\n      plt.ylabel(name)\n      if metric == 'loss':\n        plt.ylim([0, plt.ylim()[1]])\n      elif metric == 'auc':\n        plt.ylim([0.8,1])\n      else:\n        plt.ylim([0,1])\n      plt.legend()\n      plt.show()  \n    except:\n      pass\nplot_metrics(model.history)\n\nplt.title(label='Zoomed in Accuracy plot')\nplt.plot(history.history[\"accuracy\"],label='Train')\nplt.plot(history.history[\"val_accuracy\"],linestyle=\"--\",label='Validation')\nplt.legend()\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:41:06.990653Z","iopub.execute_input":"2022-04-07T11:41:06.990868Z","iopub.status.idle":"2022-04-07T11:41:07.571602Z","shell.execute_reply.started":"2022-04-07T11:41:06.990842Z","shell.execute_reply":"2022-04-07T11:41:07.570908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-cnn_dsc\"></a>\n### 3.4.5 Depthwise Separable Convolution","metadata":{}},{"cell_type":"markdown","source":"By using the depthwise and pointwise convolution we create the depthwise seprable conv used in MobileNet v1 for low computing applications. In MobileNet v2 a skip connection over the block was added and a pointwise conv before the depthwise conv within the block. (also known as **bottleneck block**) (see picture)\n\n<img src=\"https://miro.medium.com/max/448/1*fE-1I6D8A4B9QAUgZEbLUA.png\" width=\"650\" align=\"centr\"/>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.layers import Dropout, Dense, BatchNormalization, Conv2D, Flatten, MaxPool2D, Activation, Add, DepthwiseConv2D\n\nBATCH_SIZE = 32\nVAL_SPLIT = 0.1\nEPOCH_NUM = 5\nLEARNING_RATE = 0.001\nIMG_WIDTH = 180\nIMG_HEIGHT = 180\n\n\n# Defining the input size\nx_inputs = tf.keras.Input((IMG_WIDTH, IMG_HEIGHT,3))\n\nX = Conv2D(filters = 3, kernel_size = (5,5), strides = (1,1))(x_inputs)\nX = BatchNormalization(axis = 3)(X) # Default axis\nX = Activation('relu')(X)\nX = MaxPool2D(pool_size = (2,2), strides= (2,2))(X)\n\n# Save the input value. You'll need this later to add back to the main path. \nX_shortcut = X\n\nX = Conv2D(filters = 18, kernel_size = (1,1), strides = (1,1))(X)\nX = BatchNormalization(axis = 3)(X) # Default axis\nX = Activation('relu')(X)\n\nX = DepthwiseConv2D(kernel_size=(3, 3), strides=(1, 1), padding='same')(X)\nX = BatchNormalization(axis=3)(X)\nX = Activation('relu')(X)\n\nX = Conv2D(filters=3, kernel_size=(1, 1), strides=(1, 1), padding='same')(X)\nX = BatchNormalization(axis=3)(X)\nX = Activation('relu')(X)\n\n# Shortcut\nX = Add()([X, X_shortcut])\n\nX = layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(X)\nX = layers.Flatten()(X)\n\nX = tf.keras.layers.Dense(units=300, activation='relu')(X)\noutputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(X)\n\nmodel = tf.keras.Model(inputs=x_inputs, outputs=outputs)\nmodel.compile(optimizer=tf.optimizers.Adam(LEARNING_RATE) ,loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:41:07.572761Z","iopub.execute_input":"2022-04-07T11:41:07.573018Z","iopub.status.idle":"2022-04-07T11:41:07.682581Z","shell.execute_reply.started":"2022-04-07T11:41:07.572983Z","shell.execute_reply":"2022-04-07T11:41:07.681904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\ntf.keras.utils.plot_model(model,  show_shapes=True,expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:41:07.683757Z","iopub.execute_input":"2022-04-07T11:41:07.684007Z","iopub.status.idle":"2022-04-07T11:41:08.021995Z","shell.execute_reply.started":"2022-04-07T11:41:07.683975Z","shell.execute_reply":"2022-04-07T11:41:08.021175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/gpu:0'):# if no GPU is found it will run with the CPU\n    history = model.fit(x = training_set, validation_data=validation_set, epochs = EPOCH_NUM, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:41:08.023628Z","iopub.execute_input":"2022-04-07T11:41:08.024199Z","iopub.status.idle":"2022-04-07T11:41:52.968335Z","shell.execute_reply.started":"2022-04-07T11:41:08.024162Z","shell.execute_reply":"2022-04-07T11:41:52.967594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(history):\n  metrics = ['loss', 'accuracy']\n  for n, metric in enumerate(metrics):\n    try:\n      name = metric.replace(\"_\",\" \").capitalize()\n      plt.plot(history.epoch, history.history[metric], label='Train')\n      plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n      plt.xlabel('Epoch')\n      plt.ylabel(name)\n      if metric == 'loss':\n        plt.ylim([0, plt.ylim()[1]])\n      elif metric == 'auc':\n        plt.ylim([0.8,1])\n      else:\n        plt.ylim([0,1])\n      plt.legend()\n      plt.show()  \n    except:\n      pass\nplot_metrics(model.history)\n\nplt.title(label='Zoomed in Accuracy plot')\nplt.plot(history.history[\"accuracy\"],label='Train')\nplt.plot(history.history[\"val_accuracy\"],linestyle=\"--\",label='Validation')\nplt.legend()\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:41:52.970058Z","iopub.execute_input":"2022-04-07T11:41:52.97034Z","iopub.status.idle":"2022-04-07T11:41:53.560672Z","shell.execute_reply.started":"2022-04-07T11:41:52.970281Z","shell.execute_reply":"2022-04-07T11:41:53.559984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-cnn_tran\"></a>\n### 3.4.6 Transfer Learning","metadata":{}},{"cell_type":"markdown","source":"The idea of transfer learning is taking another model and deleting the output layer or several of it's layers/weights to train them again on your dataset and your specific output. This works well in CNN's because grasping features like edges and higher dimensional filters, are generally the same for most image based problems. This causes us to benefit from others well trained models.\n\n<img src=\"https://miro.medium.com/max/1400/1*f2_PnaPgA9iC5bpQaTroRw.png\" width=\"650\" align=\"centr\"/>","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image_dataset_from_directory\n\n\nBATCH_SIZE = 32\nIMG_SIZE = (160, 160)\nVAL_SPLIT = 0.2\n\ndirectory = \"../input/alpaca-dataset-small/dataset\"\n\ntrain_dataset = image_dataset_from_directory(directory,\n                                             shuffle=True,\n                                             batch_size=BATCH_SIZE,\n                                             image_size=IMG_SIZE,\n                                             validation_split=VAL_SPLIT,\n                                             subset='training',\n                                             seed=159)\nvalidation_dataset = image_dataset_from_directory(directory,\n                                             shuffle=True,\n                                             batch_size=BATCH_SIZE,\n                                             image_size=IMG_SIZE,\n                                             validation_split=VAL_SPLIT,\n                                             subset='validation',\n                                             seed=159)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:41:53.561793Z","iopub.execute_input":"2022-04-07T11:41:53.56203Z","iopub.status.idle":"2022-04-07T11:41:53.809043Z","shell.execute_reply.started":"2022-04-07T11:41:53.561997Z","shell.execute_reply":"2022-04-07T11:41:53.808295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n# I will talk more about these 2 lines of code in the Data Engineering part\nAUTOTUNE = tf.data.experimental.AUTOTUNE\ntrain_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:41:53.810187Z","iopub.execute_input":"2022-04-07T11:41:53.810447Z","iopub.status.idle":"2022-04-07T11:41:53.816761Z","shell.execute_reply.started":"2022-04-07T11:41:53.810412Z","shell.execute_reply":"2022-04-07T11:41:53.815017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to use the MobileNetV2 model to transfer learn from to classify alpaca's.","metadata":{}},{"cell_type":"code","source":"IMG_SHAPE = IMG_SIZE + (3,)\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n\n# If you want to see the model structure, uncomment the following 2 lines of code\n# base_model.summary()\n# tf.keras.utils.plot_model(base_model,  show_shapes=True,expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:41:53.818586Z","iopub.execute_input":"2022-04-07T11:41:53.819431Z","iopub.status.idle":"2022-04-07T11:41:54.917684Z","shell.execute_reply.started":"2022-04-07T11:41:53.819392Z","shell.execute_reply":"2022-04-07T11:41:54.916946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Last 2 layers of the model is considered as the top layer, if you had included the Top in previous code as True you can read them with below code. (uncomment if you want to see it)","metadata":{}},{"cell_type":"code","source":"# nb_layers = len(base_model.layers)\n# print(base_model.layers[nb_layers - 2].name)\n# print(base_model.layers[nb_layers - 1].name)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:41:54.919111Z","iopub.execute_input":"2022-04-07T11:41:54.91939Z","iopub.status.idle":"2022-04-07T11:41:54.924021Z","shell.execute_reply.started":"2022-04-07T11:41:54.919353Z","shell.execute_reply":"2022-04-07T11:41:54.92315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Freezing (part of) the model is to prevent it to relearn everything again.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.layers import Dropout, Dense, BatchNormalization, Conv2D, Flatten, MaxPool2D, Activation, Add, GlobalAveragePooling2D\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation\n\nbase_model.trainable=False\n# Make the layers trainable from layer 125 onwards\nfor layer in base_model.layers[125:]:\n    layer.trainable = True\n\nBATCH_SIZE = 32\nVAL_SPLIT = 0.1\nEPOCH_NUM = 10\nLEARNING_RATE = 0.001\nIMG_SHAPE = IMG_SIZE + (3,)\n\n# create the input layer (Same as the imageNetv2 input size)\ninputs = tf.keras.Input(IMG_SHAPE) \n\n# apply data augmentation to the inputs if you want. Or this can be done outside of the model\ndata_augmentation = RandomFlip(\"horizontal\")(inputs)\nx = RandomRotation(0.15)(data_augmentation)\n\n# data preprocessing using the same weights the model was trained on\nx = tf.keras.applications.mobilenet_v2.preprocess_input(x) \n\n# set training to False to avoid keeping track of statistics in the batch norm layer\nx = base_model(x, training=False) \n\n# using global avg pooling to summarize the info in each channel\nx = GlobalAveragePooling2D()(x) \nx = Dropout(0.3)(x)\n\noutputs = Dense(1, activation='sigmoid')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\nmodel.compile(optimizer=tf.optimizers.Adam(LEARNING_RATE) ,loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:41:54.925406Z","iopub.execute_input":"2022-04-07T11:41:54.925666Z","iopub.status.idle":"2022-04-07T11:41:55.568964Z","shell.execute_reply.started":"2022-04-07T11:41:54.925629Z","shell.execute_reply":"2022-04-07T11:41:55.568007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/gpu:0'):# if no GPU is found it will run with the CPU\n    history = model.fit(x = train_dataset, validation_data = validation_dataset, epochs = EPOCH_NUM, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:41:55.570733Z","iopub.execute_input":"2022-04-07T11:41:55.570988Z","iopub.status.idle":"2022-04-07T11:42:23.040509Z","shell.execute_reply.started":"2022-04-07T11:41:55.570954Z","shell.execute_reply":"2022-04-07T11:42:23.039765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(history):\n  metrics = ['loss', 'accuracy']\n  for n, metric in enumerate(metrics):\n    try:\n      name = metric.replace(\"_\",\" \").capitalize()\n      plt.plot(history.epoch, history.history[metric], label='Train')\n      plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n      plt.xlabel('Epoch')\n      plt.ylabel(name)\n      if metric == 'loss':\n        plt.ylim([0, plt.ylim()[1]])\n      elif metric == 'auc':\n        plt.ylim([0.8,1])\n      else:\n        plt.ylim([0,1])\n      plt.legend()\n      plt.show()  \n    except:\n      pass\nplot_metrics(model.history)\n\nplt.title(label='Zoomed in Accuracy plot')\nplt.plot(history.history[\"accuracy\"],label='Train')\nplt.plot(history.history[\"val_accuracy\"],linestyle=\"--\",label='Validation')\nplt.legend()\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T11:42:23.043397Z","iopub.execute_input":"2022-04-07T11:42:23.043611Z","iopub.status.idle":"2022-04-07T11:42:23.593924Z","shell.execute_reply.started":"2022-04-07T11:42:23.043579Z","shell.execute_reply":"2022-04-07T11:42:23.593152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cleaning up RAM\nimport gc\n\ndel train_dataset\ndel validation_dataset\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-cnn_obj\"></a>\n## 3.4.7 Object Detection","metadata":{}},{"cell_type":"markdown","source":"To understand Object Detection, we first need to refresh a few concepts.\n\nWe first want to detect the object and then classify it. This can be done all within one model, by representing our output layer as the following:\n\n**[Pc,bx,by,bh,bw,C1,C2,C3,...]**\n\nMeanings:\n\n* **Pc**(is there an object or not?)\n* **bx**(bounding box X value)\n* **by**(bounding box Y value)\n* **bh**(bounding box height)\n* **bw**(bounding box Width)\n* **C1**(class 1),**C2**(class 2),**C3**,...\n\nIf we want to detect multiple objects at the same time, we can add another of the above group to the output layer untill we are satisfied. For example: to detect 5 objects at the same time, we need 5 [Pc,bx,by,bh,bw,C1,C2,C3,...] concatenated together as output layer.\n\nIf we want to detect Landmarks. We remove the bh and bw out of the output and just save the x and y locations of each landmark instead. (example: face recognition)\n\nTo detect the position of the object, we don't want to check every pixel for an object. This would be computationally inefficient. The solution to this is splitting the image into smaller parts and only checking those for an object. This has several implementation and solutions.\n\n**Sliding windows**\n\n<img src=\"https://i.stack.imgur.com/tQZI2.jpg\" width=\"650\" align=\"centr\"/>\n\n**YOLO**\n\n(Yolo also makes use of anchor boxes, more on that later)\n\n<img src=\"https://miro.medium.com/max/1152/1*m8p5lhWdFDdapEFa2zUtIA.jpeg\" width=\"650\" align=\"centr\"/>\n\n**Non-max Suppression**\nNon-max Suppression looks at all the possible bounding boxes around an object (Intersection over Union smaller than 0.5 for example) and takes the one with the highest probability.\n\n<img src=\"https://2628535719-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-M5-0RGo4dZhdwCIHrC1%2F-M5-0TEuN77zAmTpQjIr%2F-M5-0WMNj3vkyPeFge_4%2FNon-Max%20Suppression.JPG?generation=1586990829149087&alt=media\" width=\"650\" align=\"centr\"/>\n\n**Intersection over Union**\n\n<img src=\"https://media5.datahacker.rs/2018/11/IoU.png\" width=\"650\" align=\"centr\"/>\n\n**Anchor Boxes**\n(used in YOLO)\nBy adding different styles of boxes, we can detect multiple objects of different sizes within the \"image fragment\" we are looking at.\n\n<img src=\"https://media5.datahacker.rs/2018/11/ancor_1-1.png\" width=\"650\" align=\"centr\"/>\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"cell-cnn_semantic_seg\"></a>\n## 3.4.8 Semantic Segmentation","metadata":{}},{"cell_type":"markdown","source":"Semantic segmentation is known for predicting classes on images, pixel-by-pixel. (like cars or the road)\n\n<img src=\"https://miro.medium.com/max/800/1*WKwbz04uLR0ds5M0xiCdjg.jpeg\" width=\"650\" align=\"centr\"/>\n\n**Transposed Convolution**:\n\n<img src=\"https://preview.redd.it/swxoctxkj9341.jpg?width=1210&format=pjpg&auto=webp&s=3c1e3301fae700f730b8ace194f33331ada2bdad\" width=\"650\" align=\"centr\"/>\n\nThe transposed convolution is used to upscale the dimensions in the **U-Net** architecture.\n\n<img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" width=\"650\" align=\"centr\"/>","metadata":{}},{"cell_type":"markdown","source":"The following code is heavily inspired by coursera deep learning specialization and https://www.kaggle.com/code/oluwatobiojekanmi/carla-image-semantic-segmentation-with-u-net . ","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\n# importing the data\n\nimage_path = [\"../input/lyft-udacity-challenge/\"+\"data\"+i+\"/\"+\"data\"+i+\"/CameraRGB/\" for i in ['A', 'B', 'C', 'D', 'E']]\nmask_path = [\"../input/lyft-udacity-challenge/\"+\"data\"+i+\"/\"+\"data\"+i+\"/CameraSeg/\" for i in ['A', 'B', 'C', 'D', 'E']]\n\ndef list_image_paths(directory_paths):\n    image_paths = []\n    for directory in range(len(directory_paths)):\n        image_filenames = os.listdir(directory_paths[directory])\n        for image_filename in image_filenames:\n            image_paths.append(directory_paths[directory] + image_filename)\n    return image_paths\n\nimage_paths = list_image_paths(image_path) \nmask_paths = list_image_paths(mask_path)\nnumber_of_images, number_of_masks = len(image_paths), len(mask_paths)\nprint(f\"1. There are {number_of_images} images and {number_of_masks} masks in our dataset\")\n\n# First split the image paths into training and validation sets\ntrain_image_paths, val_image_paths, train_mask_paths, val_mask_paths = train_test_split(image_paths, mask_paths, train_size=0.8, random_state=0)\n# Keep part of the validation set as test set\nvalidation_image_paths, test_image_paths, validation_mask_paths, test_mask_paths = train_test_split(val_image_paths, val_mask_paths, train_size = 0.80, random_state=0)\n\ndef read_image(image_path, mask_path):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_png(image, channels=3)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, (256, 256), method='nearest')\n\n    mask = tf.io.read_file(mask_path)\n    mask = tf.image.decode_png(mask, channels=3)\n    mask = tf.math.reduce_max(mask, axis=-1, keepdims=True)\n    mask = tf.image.resize(mask, (256, 256), method='nearest')\n    \n    return image, mask\n\ndef data_generator(image_paths, mask_paths, buffer_size, batch_size):   \n    image_list = tf.constant(image_paths) \n    mask_list = tf.constant(mask_paths)\n    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n    dataset = dataset.map(read_image, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.cache().shuffle(buffer_size).batch(batch_size)\n    \n    return dataset\n\nbatch_size = 32\nbuffer_size = 500\n\ntrain_dataset = data_generator(train_image_paths, train_mask_paths, buffer_size, batch_size)\nvalidation_dataset = data_generator(validation_image_paths, validation_mask_paths, buffer_size, batch_size)\ntest_dataset = data_generator(test_image_paths, test_mask_paths, buffer_size, batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T20:17:39.852237Z","iopub.execute_input":"2022-04-08T20:17:39.852646Z","iopub.status.idle":"2022-04-08T20:17:49.804201Z","shell.execute_reply.started":"2022-04-08T20:17:39.852611Z","shell.execute_reply":"2022-04-08T20:17:49.803412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating the model by making encoding blocks (downsampling) and decoding blocks (upsampling)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.layers import Dropout, Dense, BatchNormalization, Conv2D, Flatten, MaxPool2D, Activation, Add, GlobalAveragePooling2D, Conv2DTranspose\n\ndef conv_block(inputs=None, filters=32, dropout_prob=0, max_pooling=True):\n    \"\"\"\n    Convolutional downsampling block\n    \n    Arguments:\n        inputs -- Input tensor\n        n_filters -- Number of filters for the convolutional layers\n        dropout_prob -- Dropout probability\n        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n    Returns: \n        next_layer, skip_connection --  Next layer and skip connection outputs\n    \"\"\"\n\n    conv = Conv2D(filters, # Number of filters\n                  3,# Kernel size   \n                  padding='same',\n                  kernel_initializer= 'he_normal')(inputs)\n    conv = BatchNormalization()(conv)\n    conv = Activation(\"relu\")(conv)\n    \n    conv = Conv2D(filters, # Number of filters\n                  3,# Kernel size   \n                  padding='same',\n                  kernel_initializer= 'he_normal')(conv)\n    conv = BatchNormalization()(conv)\n    conv = Activation(\"relu\")(conv)\n    \n    # if dropout_prob > 0 add a dropout layer, with the variable dropout_prob as parameter\n    if dropout_prob > 0:\n        conv = Dropout(dropout_prob)(conv)\n        \n    # if max_pooling is True add a MaxPooling2D with 2x2 pool_size\n    if max_pooling:\n        next_layer = MaxPool2D(2,strides=2)(conv)  \n    else:\n        next_layer = conv\n        \n    skip_connection = conv\n    \n    return next_layer, skip_connection\n\ndef upsampling_block(expansive_input, contractive_input, filters=32):\n    \"\"\"\n    Convolutional upsampling block\n    \n    Arguments:\n        expansive_input -- Input tensor from previous layer\n        contractive_input -- Input tensor from previous skip layer\n        n_filters -- Number of filters for the convolutional layers\n    Returns: \n        conv -- Tensor output\n    \"\"\"\n    \n    up = Conv2DTranspose(\n                 filters,    # number of filters\n                 3,# Kernel size\n                 strides=2,\n                 padding='same')(expansive_input)\n    \n    # Merge the previous output and the contractive_input\n    merge = layers.Concatenate()([up, contractive_input])\n    \n    conv = Conv2D(filters, # Number of filters\n                  3,# Kernel size   \n                  padding='same',\n                  kernel_initializer= 'he_normal')(merge)\n    \n    conv = BatchNormalization()(merge)\n    conv = Activation(\"relu\")(conv)\n    \n    conv = Conv2D(filters, # Number of filters\n                  3,# Kernel size   \n                  padding='same',\n                  kernel_initializer= 'he_normal')(conv)\n    conv = BatchNormalization()(merge)\n    conv = Activation(\"relu\")(conv)\n    \n    return conv\n\ndef unet_model(input_size, filters=32, n_classes=23):\n    \"\"\"\n    Unet model\n    \n    Arguments:\n        input_size -- Input shape \n        n_filters -- Number of filters for the convolutional layers\n        n_classes -- Number of output classes\n    Returns: \n        model -- tf.keras.Model\n    \"\"\"\n    inputs = tf.keras.Input(input_size)\n    \n    # Contracting Path (encoding)\n    cblock1 = conv_block(inputs=inputs, filters=filters, max_pooling=True)\n    # Chain the first element of the output of each block to be the input of the next conv_block. \n    # Double the number of filters at each new step\n    \n    cblock2 = conv_block(inputs=cblock1[0], filters=filters*2, max_pooling=True)\n    cblock3 = conv_block(inputs=cblock2[0], filters=filters*4)\n\n    cblock4 = conv_block(inputs=cblock3[0], filters=filters*8, max_pooling=True)\n\n    cblock5 = conv_block(inputs=cblock4[0], filters=filters*16, dropout_prob=0.25, max_pooling=False) \n    \n    # Expanding Path (decoding)\n    # From here,at each step, use half the number of filters of the previous block \n    ublock6 = upsampling_block(cblock5[0], cblock4[1], filters*8)\n    # Chain the output of the previous block as expansive_input and the corresponding contractive block output.\n    # Note that you must use the second element of the contractive block i.e before the maxpooling layer. \n    \n    ublock7 = upsampling_block(ublock6, cblock3[1], filters*4)\n    ublock8 = upsampling_block(ublock7, cblock2[1], filters*2)\n    ublock9 = upsampling_block(ublock8, cblock1[1], filters)\n\n    conv10 = Conv2D(filters,\n                 3,\n                 activation='relu',\n                 padding='same',\n                 kernel_initializer='he_normal')(ublock9)\n\n    output = Conv2D(n_classes, kernel_size = (1,1), activation='softmax', padding='same')(conv10)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=output)\n\n    return model\n\nimg_height = 256\nimg_width = 256\nnum_channels = 3\nfilters = 32\nn_classes = 13\nLEARNING_RATE = 0.01\n\nmodel = unet_model((img_height, img_width, num_channels), filters=32, n_classes=23)\nmodel.compile(optimizer = tf.optimizers.Adam(LEARNING_RATE), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-08T20:19:28.281443Z","iopub.execute_input":"2022-04-08T20:19:28.281783Z","iopub.status.idle":"2022-04-08T20:19:28.664074Z","shell.execute_reply.started":"2022-04-08T20:19:28.281743Z","shell.execute_reply":"2022-04-08T20:19:28.663351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\ntf.keras.utils.plot_model(model,  show_shapes=True,expand_nested=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\nEPOCH_NUM = 7\n\nwith tf.device('/gpu:0'):# if no GPU is found it will run with the CPU\n    history = model.fit(x = train_dataset, validation_data = validation_dataset, epochs = EPOCH_NUM, batch_size = BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(history):\n  metrics = ['loss', 'accuracy']\n  for n, metric in enumerate(metrics):\n    try:\n      name = metric.replace(\"_\",\" \").capitalize()\n      plt.plot(history.epoch, history.history[metric], label='Train')\n      plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n      plt.xlabel('Epoch')\n      plt.ylabel(name)\n      if metric == 'loss':\n        plt.ylim([0, plt.ylim()[1]])\n      elif metric == 'auc':\n        plt.ylim([0.8,1])\n      else:\n        plt.ylim([0,1])\n      plt.legend()\n      plt.show()  \n    except:\n      pass\nplot_metrics(model.history)\n\nplt.title(label='Zoomed in Accuracy plot')\nplt.plot(history.history[\"accuracy\"],label='Train')\nplt.plot(history.history[\"val_accuracy\"],linestyle=\"--\",label='Validation')\nplt.legend()\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cleaning up RAM\nimport gc\n\ndel train_dataset\ndel validation_dataset\ndel test_dataset\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T20:34:56.676848Z","iopub.execute_input":"2022-04-08T20:34:56.677337Z","iopub.status.idle":"2022-04-08T20:35:48.838473Z","shell.execute_reply.started":"2022-04-08T20:34:56.677299Z","shell.execute_reply":"2022-04-08T20:35:48.837784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-cnn_face_rec\"></a>\n## 3.4.9 Facial Recognition","metadata":{}},{"cell_type":"markdown","source":"To recognize someone, we make use of the triplet loss function **Triplet loss** is a loss function for machine learning algorithms where a reference input (called anchor) is compared to a matching input (called positive) and a non-matching input (called negative).\n\nThe \"distance\" between these are being compared and if they are below/above a certain treshhold, they will result as a match or not.\n\n<img src=\"https://miro.medium.com/max/1302/1*SKWGC3ehCbGCsbJVge6kmg.png\" width=\"650\" align=\"centr\"/>\n\nI recommend using **FaceNet** model and transfer learn it for your project to start out.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"cell-cnn_style_transf\"></a>\n## 3.4.10 Neural Style Transfer","metadata":{}},{"cell_type":"markdown","source":"We take an image (content) and merge it together with a specific style (another image).\n\n<img src=\"https://hackernoon.com/hn-images/1*k5Q_NYr1niC-qjWMr-lUCg.png\" width=\"650\" align=\"centr\"/>\n\nWe calculate the cost function based on following formula between the style and the content:\n\n<img src=\"https://assets.website-files.com/5ac6b7f2924c652fd013a891/5ddd8faa5ec068074fc684b0_Tcyrhi9Soqdop2OAXQoz2yg25nCsdrBNAWWTYzdNK83V8srvlMJJv9KXmQR9PC6Pa_ktiwdvdc-CBhRNX_CsaQcl0oKS92_gSjDj0q9xKigaipvuqQHWFAtEE6a3ulK_znVZ_tI.png\" width=\"650\" align=\"centr\"/>\n\n<img src=\"https://miro.medium.com/max/1294/1*ZgW520SZr1QkGoFd3xqYMw.jpeg\" width=\"650\" align=\"centr\"/>\n\n**Approach**: We load a pre-trained model like VGG/ImageNet/MobileNet/ResNet remove the top and implement the cost function around the middle layers of the pretrained model. (This works as these pretrained models have well trained layers to capture features of the image) We try to capture both the shallow and deeper features by implementing it around the middle layers of the model.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"cell-rnn\"></a>\n## 3.5 Recurrent Neural Networks (RNN)","metadata":{"id":"3hSm_Dt8BkgH"}},{"cell_type":"markdown","source":"<a id=\"cell-rnn_data\"></a>\n### Importing Simple Data","metadata":{"id":"ls2H-frAB9O1"}},{"cell_type":"code","source":"!pip install yfinance\nimport yfinance as yf","metadata":{"execution":{"iopub.status.busy":"2022-04-09T17:17:46.577865Z","iopub.execute_input":"2022-04-09T17:17:46.578348Z","iopub.status.idle":"2022-04-09T17:17:57.402467Z","shell.execute_reply.started":"2022-04-09T17:17:46.578312Z","shell.execute_reply":"2022-04-09T17:17:57.401575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nWINDOW_SIZE = 40\n\naapl = yf.Ticker(\"AAPL\")\nX = aapl.history(\"max\").loc[:,['Close']]\ny = X[WINDOW_SIZE:]\n\n# Scale the data\nscaler = MinMaxScaler()\nX_scaled = scaler.fit_transform(X)\ny_scaled = scaler.transform(y)\n\n# putting WINDOW_SIZE amount of datapoints in a list which rolls over throughout the data. This is used as input for the neural network\nX_df = []\nfor i in range(WINDOW_SIZE, len(X_scaled)):\n    X_df.append(X_scaled[i-WINDOW_SIZE:i])\n\nprint(np.shape(X_df))\nX_train, X_test, y_train, y_test = train_test_split(X_df, y_scaled, test_size = 0.2, random_state = 0, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T17:18:14.15856Z","iopub.execute_input":"2022-04-09T17:18:14.158934Z","iopub.status.idle":"2022-04-09T17:18:15.150104Z","shell.execute_reply.started":"2022-04-09T17:18:14.158885Z","shell.execute_reply":"2022-04-09T17:18:15.14927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-rnn_lstm\"></a>\n## 3.5.1 Long short-term memory (LSTM)","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://miro.medium.com/max/674/1*jikKbzFXCq-IYnFZankIMg.png\" width=\"650\" align=\"centr\"/>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.layers import Dropout, Dense, BatchNormalization, LSTM, Activation, Reshape\n\nBATCH_SIZE = 32\nVAL_SPLIT = 0.1\nEPOCH_NUM = 5\nLEARNING_RATE = 0.01\nWINDOW_SIZE = 40\n\n# Defining the input size\nx_inputs = tf.keras.Input((WINDOW_SIZE, 1))\n\n# If we are working with text, we might use Bidirectional LSTM\nx = LSTM(units = 40, return_sequences=False)(x_inputs)\nx = Dense(units = 16, activation = 'relu')(x)\n\noutput = Dense(units = 1, activation = 'linear')(x)\n\nmodel = tf.keras.Model(inputs=x_inputs, outputs=output)\nmodel.compile(optimizer=tf.optimizers.Adam(LEARNING_RATE), loss='mse',metrics=['mse'])","metadata":{"execution":{"iopub.status.busy":"2022-04-09T18:31:19.473489Z","iopub.execute_input":"2022-04-09T18:31:19.473752Z","iopub.status.idle":"2022-04-09T18:31:19.709707Z","shell.execute_reply.started":"2022-04-09T18:31:19.473722Z","shell.execute_reply":"2022-04-09T18:31:19.708983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\ntf.keras.utils.plot_model(model,  show_shapes=True,expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T18:31:23.391831Z","iopub.execute_input":"2022-04-09T18:31:23.392381Z","iopub.status.idle":"2022-04-09T18:31:23.611601Z","shell.execute_reply.started":"2022-04-09T18:31:23.392333Z","shell.execute_reply":"2022-04-09T18:31:23.610817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/gpu:0'):# if no GPU is found it will run with the CPU\n    history = model.fit(x = np.array(X_train), y = np.array(y_train), validation_split = VAL_SPLIT, epochs = EPOCH_NUM, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T18:31:32.704189Z","iopub.execute_input":"2022-04-09T18:31:32.70447Z","iopub.status.idle":"2022-04-09T18:31:44.161236Z","shell.execute_reply.started":"2022-04-09T18:31:32.70444Z","shell.execute_reply":"2022-04-09T18:31:44.160472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(history):\n  metrics = ['loss', 'mse']\n  for n, metric in enumerate(metrics):\n    try:\n      name = metric.replace(\"_\",\" \").capitalize()\n      plt.plot(history.epoch, history.history[metric], label='Train')\n      plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n      plt.xlabel('Epoch')\n      plt.ylabel(name)\n      if metric == 'loss':\n        plt.ylim([0, plt.ylim()[1]])\n      elif metric == 'auc':\n        plt.ylim([0.8,1])\n      else:\n        plt.ylim([0,1])\n      plt.legend()\n      plt.show()  \n    except:\n      pass\nplot_metrics(model.history)\n\nplt.title(label='Zoomed in mse plot')\nplt.plot(history.history[\"mse\"],label='Train')\nplt.plot(history.history[\"val_mse\"],linestyle=\"--\",label='Validation')\nplt.legend()\nplt.ylabel('mse')\nplt.xlabel('Epoch')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T18:30:48.207398Z","iopub.execute_input":"2022-04-09T18:30:48.207674Z","iopub.status.idle":"2022-04-09T18:30:48.778931Z","shell.execute_reply.started":"2022-04-09T18:30:48.207644Z","shell.execute_reply":"2022-04-09T18:30:48.778251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(np.array(X_test))\n\nplt.title(\"Test data compared to prediction\")\nplt.plot(range(len(pred)), pred, label='Predicted')\nplt.plot(range(len(y_test)), y_test, label='Real Price')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T18:32:06.743821Z","iopub.execute_input":"2022-04-09T18:32:06.744599Z","iopub.status.idle":"2022-04-09T18:32:07.505538Z","shell.execute_reply.started":"2022-04-09T18:32:06.744555Z","shell.execute_reply":"2022-04-09T18:32:07.504709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-nlp\"></a>\n## 3.6 Natural Language Processing (NLP)","metadata":{"id":"f1ILRTILq4W7"}},{"cell_type":"markdown","source":"<a id=\"cell-nlp_sent\"></a>\n## 3.6.1 Sentiment Analysis","metadata":{}},{"cell_type":"markdown","source":"Project approach:\n\n* Clean the data by deleting Stopwords, Stemming and put it all into the \"corpus\"\n* Tokenize your corpus with \"bag of words\" or term frequency-inverse document frequency (TF-IDF)\n* Train the model\n\n**Corpus**: A corpus is a collection of authentic text or audio organized into dataset.\n\n**Stemming**: Stemming is the process of reducing a word to one or more stems. A stemming dictionary maps a word to its lemma (stem)\n\n**Tokenization**: Tokenization is the process of representing raw text in smaller units called tokens. These tokens can then be mapped with numbers to further feed to an NLP model\n\nTF-IDF: \n\n<img src=\"https://miro.medium.com/max/661/1*3K9GIOVLNu0cRvQap_KaRg.png\" width=\"650\" align=\"centr\"/>\n\nAs I did not cover the BERT model, which can be used for a wide variety of NLP tasks, I would like to recommend to also check this notebook as a better coverage of the topic. https://www.kaggle.com/code/andreshg/nlp-glove-bert-tf-idf-lstm-explained","metadata":{}},{"cell_type":"code","source":"# importing the training data\nimdb_data = pd.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\nprint(imdb_data.shape)\nimdb_data.head(10)","metadata":{"id":"w7Tmq625rOwm","executionInfo":{"status":"ok","timestamp":1649077180884,"user_tz":-120,"elapsed":424,"user":{"displayName":"Robin Van Craenenbroek","userId":"13280920442299608983"}},"outputId":"e1880759-b6c2-41bb-8ed9-9a099f458e6c","execution":{"iopub.status.busy":"2022-04-11T21:17:19.169478Z","iopub.execute_input":"2022-04-11T21:17:19.169728Z","iopub.status.idle":"2022-04-11T21:17:20.611118Z","shell.execute_reply.started":"2022-04-11T21:17:19.1697Z","shell.execute_reply":"2022-04-11T21:17:20.610433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom bs4 import BeautifulSoup\nimport re\n\nimdb_data_len = len(imdb_data.iloc[:, 0])\nall_stopwords = stopwords.words('english')\nall_stopwords.remove('not')\n\nps = PorterStemmer()\n\n# new list with cleaned data\ncorpus = []\nfor i in range(imdb_data_len): # this can also be written as imdb_data['review']\n  review = BeautifulSoup(imdb_data['review'][i], \"html.parser\").get_text()\n  review = re.sub('\\[[^]]*\\]',' ',review)\n  review = re.sub('[^a-zA-z0-9]',' ',review)\n  review = review.lower()\n  review = review.split()\n\n  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n  review = ' '.join(review)\n\n  corpus.append(review)\n    \nprint(\"Done cleaning the data!\")","metadata":{"execution":{"iopub.status.busy":"2022-04-11T21:17:25.694557Z","iopub.execute_input":"2022-04-11T21:17:25.694834Z","iopub.status.idle":"2022-04-11T21:21:01.255981Z","shell.execute_reply.started":"2022-04-11T21:17:25.694785Z","shell.execute_reply":"2022-04-11T21:21:01.254329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n#Tfidf vectorizer\ntv = TfidfVectorizer(max_features = 1500)\nx = tv.fit_transform(corpus).toarray()\ny = imdb_data.iloc[:,1].values","metadata":{"execution":{"iopub.status.busy":"2022-04-11T21:21:18.5852Z","iopub.execute_input":"2022-04-11T21:21:18.585462Z","iopub.status.idle":"2022-04-11T21:21:25.088856Z","shell.execute_reply.started":"2022-04-11T21:21:18.585432Z","shell.execute_reply":"2022-04-11T21:21:25.087985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)\n\nfrom sklearn.linear_model import LogisticRegression\n\nclassifier_LR = LogisticRegression(max_iter = 500,random_state = 0)\nclassifier_LR.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T21:21:32.908561Z","iopub.execute_input":"2022-04-11T21:21:32.908858Z","iopub.status.idle":"2022-04-11T21:21:36.50484Z","shell.execute_reply.started":"2022-04-11T21:21:32.908826Z","shell.execute_reply":"2022-04-11T21:21:36.504074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\ny_pred_LR = classifier_LR.predict(x_test)\ncm = confusion_matrix(y_test, y_pred_LR)\nprint(cm)\nprint(accuracy_score(y_test, y_pred_LR))","metadata":{"execution":{"iopub.status.busy":"2022-04-11T21:23:22.911532Z","iopub.execute_input":"2022-04-11T21:23:22.91183Z","iopub.status.idle":"2022-04-11T21:23:23.089872Z","shell.execute_reply.started":"2022-04-11T21:23:22.911782Z","shell.execute_reply":"2022-04-11T21:23:23.089116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n\ndel x\ndel y\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T21:25:11.679674Z","iopub.execute_input":"2022-04-11T21:25:11.680482Z","iopub.status.idle":"2022-04-11T21:25:11.82768Z","shell.execute_reply.started":"2022-04-11T21:25:11.680441Z","shell.execute_reply":"2022-04-11T21:25:11.826666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cell-references\"></a>\n# 4. References","metadata":{}},{"cell_type":"markdown","source":"I would like to give credit to all Dataset Providers and the Udemy/Coursera courses who taught me most of my knowledge. I would also like to thank the Kaggle community to providing Educational projects that helped me better understand the concepts within Artificial Intelligence.","metadata":{}}]}